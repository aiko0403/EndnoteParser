{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf190
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs24 \cf0 @ARTICLE\{6165133, \
author=\{Yunhua Deng and Lau, Rynson W H\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{On Delay Adjustment for Dynamic Load Balancing in Distributed Virtual Environments\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{529-537\}, \
abstract=\{Distributed virtual environments (DVEs) are becoming very popular in recent years, due to the rapid growing of applications, such as massive multiplayer online games (MMOGs). As the number of concurrent users increases, scalability becomes one of the major challenges in designing an interactive DVE system. One solution to address this scalability problem is to adopt a multi-server architecture. While some methods focus on the quality of partitioning the load among the servers, others focus on the efficiency of the partitioning process itself. However, all these methods neglect the effect of network delay among the servers on the accuracy of the load balancing solutions. As we show in this paper, the change in the load of the servers due to network delay would affect the performance of the load balancing algorithm. In this work, we conduct a formal analysis of this problem and discuss two efficient delay adjustment schemes to address the problem. Our experimental results show that our proposed schemes can significantly improve the performance of the load balancing algorithm with neglectable computation overhead.\}, \
keywords=\{formal specification;formal verification;resource allocation;virtual reality;delay adjustment schemes;distributed virtual environment;dynamic load balancing algorithm;formal analysis;interactive DVE system;load partitioning;massive multiplayer online game;multiserver architecture;network delay effect;server load;Delay;Heating;Heuristic algorithms;Load management;Load modeling;Servers;Silicon;Multi-server architecture;delay adjustment;distributed virtual environments.;dynamic load balancing;Computer Communication Networks;Computer Graphics;Humans;Online Systems;User-Computer Interface;Video Games\}, \
doi=\{10.1109/TVCG.2012.52\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165134, \
author=\{Bruder, G. and Interrante, V. and Phillips, L. and Steinicke, F.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Redirecting Walking and Driving for Natural Navigation in Immersive Virtual Environments\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{538-545\}, \
abstract=\{Walking is the most natural form of locomotion for humans, and real walking interfaces have demonstrated their benefits for several navigation tasks. With recently proposed redirection techniques it becomes possible to overcome space limitations as imposed by tracking sensors or laboratory setups, and, theoretically, it is now possible to walk through arbitrarily large virtual environments. However, walking as sole locomotion technique has drawbacks, in particular, for long distances, such that even in the real world we tend to support walking with passive or active transportation for longer-distance travel. In this article we show that concepts from the field of redirected walking can be applied to movements with transportation devices. We conducted psychophysical experiments to determine perceptual detection thresholds for redirected driving, and set these in relation to results from redirected walking. We show that redirected walking-and-driving approaches can easily be realized in immersive virtual reality laboratories, e. g., with electric wheelchairs, and show that such systems can combine advantages of real walking in confined spaces with benefits of using vehiclebased self-motion for longer-distance travel.\}, \
keywords=\{interactive devices;user interfaces;virtual reality;active transportation;driving locomotion;electric wheelchair;immersive virtual environment;longer-distance travel;natural navigation;navigation task;passive transportation;perceptual detection threshold;redirected driving;redirected walking;redirection technique;transportation device;vehicle-based self-motion;walking interface;walking locomotion;Laboratories;Legged locomotion;Navigation;Space exploration;Vehicles;Visualization;Wheelchairs;Redirected walking;motion perception.;natural locomotion;redirected driving;self&#8211;Automobile Driving;Computer Graphics;Humans;Psychophysics;Space Perception;User-Computer Interface;Walking;Wheelchairs\}, \
doi=\{10.1109/TVCG.2012.55\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165135, \
author=\{Cirio, G. and Vangorp, P. and Chapoulie, E. and Marchal, M. and Lecuyer, A. and Drettakis, G.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Walking in a Cube: Novel Metaphors for Safely Navigating Large Virtual Environments in Restricted Real Workspaces\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{546-554\}, \
abstract=\{Immersive spaces such as 4-sided displays with stereo viewing and high-quality tracking provide a very engaging and realistic virtual experience. However, walking is inherently limited by the restricted physical space, both due to the screens (limited translation) and the missing back screen (limited rotation). In this paper, we propose three novel locomotion techniques that have three concurrent goals: keep the user safe from reaching the translational and rotational boundaries; increase the amount of real walking and finally, provide a more enjoyable and ecological interaction paradigm compared to traditional controller-based approaches. We notably introduce the "Virtual Companion", which uses a small bird to guide the user through VEs larger than the physical space. We evaluate the three new techniques through a user study with travel-to-target and path following tasks. The study provides insight into the relative strengths of each new technique for the three aforementioned goals. Specifically, if speed and accuracy are paramount, traditional controller interfaces augmented with our novel warning techniques may be more appropriate; if physical walking is more important, two of our paradigms (extended Magic Barrier Tape and Constrained Wand) should be preferred; last, fun and ecological criteria would favor the Virtual Companion.\}, \
keywords=\{computer displays;user interfaces;virtual reality;4-sided display;constrained wand paradigm;controller interface;controller-based approach;ecological interaction paradigm;high-quality tracking;immersive space;limited rotation;limited translation;locomotion technique;magic barrier tape paradigm;path following task;rotational boundary;stereo viewing;translational boundary;travel-to-target task;user study;virtual companion;virtual environment navigation;virtual experience;warning technique;Birds;Face;Legged locomotion;Navigation;Safety;Virtual environments;Visualization;Virtual reality;locomotion techniques;restricted workspaces.;walking;Computer Graphics;Humans;Space Perception;User-Computer Interface;Walking;Workplace\}, \
doi=\{10.1109/TVCG.2012.60\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165136, \
author=\{Suma, E.A. and Lipps, Z. and Finkelstein, S. and Krum, D.M. and Bolas, M.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Impossible Spaces: Maximizing Natural Walking in Virtual Environments with Self-Overlapping Architecture\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{555-564\}, \
abstract=\{Walking is only possible within immersive virtual environments that fit inside the boundaries of the user's physical workspace. To reduce the severity of the restrictions imposed by limited physical area, we introduce "impossible spaces," a new design mechanic for virtual environments that wish to maximize the size of the virtual environment that can be explored with natural locomotion. Such environments make use of self-overlapping architectural layouts, effectively compressing comparatively large interior environments into smaller physical areas. We conducted two formal user studies to explore the perception and experience of impossible spaces. In the first experiment, we showed that reasonably small virtual rooms may overlap by as much as 56% before users begin to detect that they are in an impossible space, and that the larger virtual rooms that expanded to maximally fill our available 9.14m \'d7 9.14m workspace may overlap by up to 31%. Our results also demonstrate that users perceive distances to objects in adjacent overlapping rooms as if the overall space was uncompressed, even at overlap levels that were overtly noticeable. In our second experiment, we combined several well-known redirection techniques to string together a chain of impossible spaces in an expansive outdoor scene. We then conducted an exploratory analysis of users' verbal feedback during exploration, which indicated that impossible spaces provide an even more powerful illusion when users are naive to the manipulation.\}, \
keywords=\{feedback;gait analysis;human computer interaction;virtual reality;adjacent overlapping room;design mechanic;expansive outdoor scene;illusion;immersive virtual environment;impossible spaces;natural locomotion;natural walking;redirection technique;self-overlapping architectural layout;user physical workspace;users verbal feedback;virtual room;Buildings;Educational institutions;Estimation;Layout;Legged locomotion;Space exploration;Virtual environments;Virtual environments;perception;redirection.;spatial illusions;Adult;Architecture as Topic;Computer Graphics;Distance Perception;Environment;Female;Humans;Male;Middle Aged;Motion Sickness;Space Perception;User-Computer Interface;Walking;Young Adult\}, \
doi=\{10.1109/TVCG.2012.47\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165137, \
author=\{Veas, E. and Grasset, R. and Kruijff, E. and Schmalstieg, D.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Extended Overview Techniques for Outdoor Augmented Reality\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{565-572\}, \
abstract=\{In this paper, we explore techniques that aim to improve site understanding for outdoor Augmented Reality (AR) applications. While the first person perspective in AR is a direct way of filtering and zooming on a portion of the data set, it severely narrows overview of the situation, particularly over large areas. We present two interactive techniques to overcome this problem: multi-view AR and variable perspective view. We describe in details the conceptual, visualization and interaction aspects of these techniques and their evaluation through a comparative user study. The results we have obtained strengthen the validity of our approach and the applicability of our methods to a large range of application domains.\}, \
keywords=\{augmented reality;comparative user study;data set portion filtering;data set portion zooming;extended overview techniques;multiview AR interactive techniques;outdoor augmented reality application;site understanding;variable perspective view interactive techniques;Cameras;Context;Data visualization;Mobile communication;Navigation;Solid modeling;Three dimensional displays;Information Interfaces and Presentation;mobile augmented reality;multi-perspective views;navigation.;situation awareness;Adult;Computer Graphics;Environment;Female;Humans;Male;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2012.44\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165138, \
author=\{Yanli Liu and Granier, X.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Online Tracking of Outdoor Lighting Variations for Augmented Reality with Moving Cameras\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{573-580\}, \
abstract=\{In augmented reality, one of key tasks to achieve a convincing visual appearance consistency between virtual objects and video scenes is to have a coherent illumination along the whole sequence. As outdoor illumination is largely dependent on the weather, the lighting condition may change from frame to frame. In this paper, we propose a full image-based approach for online tracking of outdoor illumination variations from videos captured with moving cameras. Our key idea is to estimate the relative intensities of sunlight and skylight via a sparse set of planar feature-points extracted from each frame. To address the inevitable feature misalignments, a set of constraints are introduced to select the most reliable ones. Exploiting the spatial and temporal coherence of illumination, the relative intensities of sunlight and skylight are finally estimated by using an optimization process. We validate our technique on a set of real-life videos and show that the results with our estimations are visually coherent along the video sequences.\}, \
keywords=\{augmented reality;cameras;feature extraction;image sequences;lighting;object tracking;optimisation;video signal processing;augmented reality;full image-based approach;illumination;lighting condition;moving camera;online tracking;optimization process;outdoor lighting variation;planar feature point extraction;skylight relative intensity;spatial coherence;sunlight relative intensity;temporal coherence;video scene;video sequence;virtual object;visual appearance consistency;Buildings;Cameras;Estimation;Feature extraction;Geometry;Lighting;Three dimensional displays;Augmented reality;illumination coherence;moving cameras.;Algorithms;Computer Graphics;Humans;Lighting;Motion;User-Computer Interface;Video Recording\}, \
doi=\{10.1109/TVCG.2012.53\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165139, \
author=\{Pollock, B. and Burton, M. and Kelly, J.W. and Gilbert, S. and Winer, E.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{The Right View from the Wrong Location: Depth Perception in Stereoscopic Multi-User Virtual Environments\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{581-588\}, \
abstract=\{Stereoscopic depth cues improve depth perception and increase immersion within virtual environments (VEs). However, improper display of these cues can distort perceived distances and directions. Consider a multi-user VE, where all users view identical stereoscopic images regardless of physical location. In this scenario, cues are typically customized for one "leader" equipped with a head-tracking device. This user stands at the center of projection (CoP) and all other users ("followers") view the scene from other locations and receive improper depth cues. This paper examines perceived depth distortion when viewing stereoscopic VEs from follower perspectives and the impact of these distortions on collaborative spatial judgments. Pairs of participants made collaborative depth judgments of virtual shapes viewed from the CoP or after displacement forward or backward. Forward and backward displacement caused perceived depth compression and expansion, respectively, with greater compression than expansion. Furthermore, distortion was less than predicted by a ray-intersection model of stereo geometry. Collaboration times were significantly longer when participants stood at different locations compared to the same location, and increased with greater perceived depth discrepancy between the two viewing locations. These findings advance our understanding of spatial distortions in multi-user VEs, and suggest a strategy for reducing distortion.\}, \
keywords=\{computer displays;stereo image processing;user interfaces;virtual reality;backward displacement;center-of-projection;collaborative spatial judgment;depth perception;distortion reduction strategy;follower perspective;forward displacement;head-tracking device;immersion;leader perspective;perceived depth compression;perceived depth expansion;ray-intersection model;stereo geometry;stereoscopic depth cue;stereoscopic displays;stereoscopic image;stereoscopic multiuser virtual environment;virtual shape;Collaboration;Educational institutions;Predictive models;Shape;Stereo image processing;Virtual environments;Perception;and collaborative interaction.;stereoscopy;Computer Graphics;Depth Perception;Environment;Female;Humans;Male;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2012.58\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165140, \
author=\{Kellner, F. and Bolte, B. and Bruder, G. and Rautenberg, U. and Steinicke, F. and Lappe, M. and Koch, R.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Geometric Calibration of Head-Mounted Displays and its Effects on Distance Estimation\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{589-596\}, \
abstract=\{Head-mounted displays (HMDs) allow users to observe virtual environments (VEs) from an egocentric perspective. However, several experiments have provided evidence that egocentric distances are perceived as compressed in VEs relative to the real world. Recent experiments suggest that the virtual view frustum set for rendering the VE has an essential impact on the user's estimation of distances. In this article we analyze if distance estimation can be improved by calibrating the view frustum for a given HMD and user. Unfortunately, in an immersive virtual reality (VR) environment, a full per user calibration is not trivial and manual per user adjustment often leads to mini- or magnification of the scene. Therefore, we propose a novel per user calibration approach with optical see-through displays commonly used in augmented reality (AR). This calibration takes advantage of a geometric scheme based on 2D point - 3D line correspondences, which can be used intuitively by inexperienced users and requires less than a minute to complete. The required user interaction is based on taking aim at a distant target marker with a close marker, which ensures non-planar measurements covering a large area of the interaction space while also reducing the number of required measurements to five. We found the tendency that a calibrated view frustum reduced the average distance underestimation of users in an immersive VR environment, but even the correctly calibrated view frustum could not entirely compensate for the distance underestimation effects.\}, \
keywords=\{augmented reality;calibration;helmet mounted displays;human computer interaction;rendering (computer graphics);2D point-3D line correspondences;HMD;augmented reality;average distance underestimation reduction;calibrated view frustum;distance estimation;distance underestimation effects;egocentric distance;egocentric perspective;full per user calibration;geometric calibration;geometric scheme;head-mounted display;immersive VR environment;immersive virtual reality environment;manual per user adjustment;optical see-through display;rendering;user interaction;virtual view frustum set;Calibration;Cameras;Estimation;Noise;Target tracking;Three dimensional displays;Vectors;HMD calibration;Optical see-through;distance perception.;Adult;Calibration;Computer Graphics;Computer Simulation;Distance Perception;Equipment Design;Female;Head;Humans;Male;Rotation;User-Computer Interface;Young Adult\}, \
doi=\{10.1109/TVCG.2012.45\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165141, \
author=\{Laha, Bireswar and Sensharma, K. and Schiffbauer, J.D. and Bowman, D.A.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Effects of Immersion on Visual Analysis of Volume Data\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{597-606\}, \
abstract=\{Volume visualization has been widely used for decades for analyzing datasets ranging from 3D medical images to seismic data to paleontological data. Many have proposed using immersive virtual reality (VR) systems to view volume visualizations, and there is anecdotal evidence of the benefits of VR for this purpose. However, there has been very little empirical research exploring the effects of higher levels of immersion for volume visualization, and it is not known how various components of immersion influence the effectiveness of visualization in VR. We conducted a controlled experiment in which we studied the independent and combined effects of three components of immersion (head tracking, field of regard, and stereoscopic rendering) on the effectiveness of visualization tasks with two x-ray microscopic computed tomography datasets. We report significant benefits of analyzing volume data in an environment involving those components of immersion. We find that the benefits do not necessarily require all three components simultaneously, and that the components have variable influence on different task categories. The results of our study improve our understanding of the effects of immersion on perceived and actual task performance, and provide guidance on the choice of display systems to designers seeking to maximize the effectiveness of volume visualization applications.\}, \
keywords=\{computerised tomography;data analysis;data visualisation;rendering (computer graphics);virtual reality;3D medical image;display system;field-of-regard component;head tracking component;immersion effect;immersive VR system;immersive virtual reality systems;paleontological data;perceived task performance;seismic data;stereoscopic rendering component;visual analysis;volume data analysis;volume visualization;x-ray microscopic computed tomography dataset;Data visualization;Head;Mice;Rendering (computer graphics);Three dimensional displays;Training;Visualization;3D visualization;CAVE;Immersion;data analysis;micro-CT;virtual environments;virtual reality.;volume visualization;Adolescent;Adult;Animals;Computer Graphics;Databases, Factual;Extremities;Female;Fossils;Humans;Imaging, Three-Dimensional;Male;Mice;Task Performance and Analysis;Tissue Scaffolds;User-Computer Interface;X-Ray Microtomography;Young Adult\}, \
doi=\{10.1109/TVCG.2012.42\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165142, \
author=\{Ponto, K. and Kohlmann, J. and Gleicher, M.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Effective Replays and Summarization of Virtual Experiences\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{607-616\}, \
abstract=\{Direct replay of the experience of a user in a virtual environment is difficult for others to watch due to unnatural camera motions. We present methods for replaying and summarizing these egocentric experiences that effectively communicate the user's observations while reducing unwanted camera movements. Our approach summarizes the viewpoint path as a concise sequence of viewpoints that cover the same parts of the scene. The core of our approach is a novel content-dependent metric that can be used to identify similarities between viewpoints. This enables viewpoints to be grouped by similar contextual view information and provides a means to generate novel viewpoints that can encapsulate a series of views. These resulting encapsulated viewpoints are used to synthesize new camera paths that convey the content of the original viewer's experience. Projecting the initial movement of the user back on the scene can be used to convey the details of their observations, and the extracted viewpoints can serve as bookmarks for control or analysis. Finally we present performance analysis along with two forms of validation to test whether the extracted viewpoints are representative of the viewer's original observations and to test for the overall effectiveness of the presented replay methods.\}, \
keywords=\{cameras;virtual reality;content-dependent metric;contextual view information;egocentric experiences;performance analysis;unnatural camera motions;user observations;viewpoint extraction;viewpoint path summarization;virtual environment;virtual experience replay;virtual experience summarization;Cameras;Equations;Geometry;Graphics processing unit;Measurement;Three dimensional displays;Virtual environments;Bookmarking.;GPU;Summarization;Viewpoint Similarity;Virtual Reality;Computer Graphics;Humans;Motion;Movement;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2012.41\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165143, \
author=\{Ullrich, S. and Kuhlen, T.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Haptic Palpation for Medical Simulation in Virtual Environments\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{617-625\}, \
abstract=\{Palpation is a physical examination technique where objects, e.g., organs or body parts, are touched with fingers to determine their size, shape, consistency and location. Many medical procedures utilize palpation as a supplementary interaction technique and it can be therefore considered as an essential basic method. However, palpation is mostly neglected in medical training simulators, with the exception of very specialized simulators that solely focus on palpation, e.g., for manual cancer detection. In this article we propose a novel approach to enable haptic palpation interaction for virtual reality-based medical simulators. The main contribution is an extensive user study conducted with a large group of medical experts. To provide a plausible simulation framework for this user study, we contribute a novel and detailed interaction algorithm for palpation with tissue dragging, which utilizes a multi-object force algorithm to support multiple layers of anatomy and a pulse force algorithm for simulation of an arterial pulse. Furthermore, we propose a modification for an off-the-shelf haptic device by adding a lightweight palpation pad to support a more realistic finger grip configuration for palpation tasks. The user study itself has been conducted on a medical training simulator prototype with a specific procedure from regional anesthesia, which strongly depends on palpation. The prototype utilizes a co-rotational finite-element approach for soft tissue simulation and provides bimanual interaction by combining the aforementioned techniques with needle insertion for the other hand. The results of the user study suggest reasonable face validity of the simulator prototype and in particular validate medical plausibility of the proposed palpation interaction algorithm.\}, \
keywords=\{computer based training;finite element analysis;haptic interfaces;medical computing;user interfaces;virtual reality;anatomy layer support;arterial pulse simulation;bimanual interaction;corotational finite-element approach;finger grip configuration;haptic device;haptic palpation;manual cancer detection;medical procedure;medical simulation;medical training simulator;multiobject force algorithm;needle insertion;palpation examination technique;pulse force algorithm;regional anesthesia;soft tissue simulation;supplementary interaction technique;tissue dragging;user study;virtual environment;virtual reality-based medical simulator;Bismuth;Force;Haptic interfaces;Phantoms;Rendering (computer graphics);Skin;Visualization;Medicine;haptics;physically-based simulation;user studies.;Adult;Algorithms;Anesthesiology;Biophysical Phenomena;Computer Graphics;Computer-Assisted Instruction;Female;Humans;Internship and Residency;Male;Middle Aged;Palpation;Phantoms, Imaging;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2012.46\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165144, \
author=\{McMahan, R.P. and Bowman, D.A. and Zielinski, D.J. and Brady, R.B.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Evaluating Display Fidelity and Interaction Fidelity in a Virtual Reality Game\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{626-633\}, \
abstract=\{In recent years, consumers have witnessed a technological revolution that has delivered more-realistic experiences in their own homes through high-definition, stereoscopic televisions and natural, gesture-based video game consoles. Although these experiences are more realistic, offering higher levels of fidelity, it is not clear how the increased display and interaction aspects of fidelity impact the user experience. Since immersive virtual reality (VR) allows us to achieve very high levels of fidelity, we designed and conducted a study that used a six-sided CAVE to evaluate display fidelity and interaction fidelity independently, at extremely high and low levels, for a VR first-person shooter (FPS) game. Our goal was to gain a better understanding of the effects of fidelity on the user in a complex, performance-intensive context. The results of our study indicate that both display and interaction fidelity significantly affect strategy and performance, as well as subjective judgments of presence, engagement, and usability. In particular, performance results were strongly in favor of two conditions: low-display, low-interaction fidelity (representative of traditional FPS games) and high-display, high-interaction fidelity (similar to the real world).\}, \
keywords=\{computer games;display instrumentation;human computer interaction;virtual reality;VR first-person shooter game;display fidelity evaluation;high-display condition;high-interaction fidelity condition;immersive virtual reality;interaction fidelity evaluation;low-display condition;low-interaction fidelity condition;performance-intensive context;six-sided CAVE;subjective engagement judgement;subjective presence judgement;subjective usability judgement;user experience;virtual reality game;Accuracy;Games;Humans;Keyboards;Mice;Turning;Usability;Virtual reality;display fidelity;engagement.;interaction fidelity;presence;Adolescent;Adult;Computer Graphics;Computer Simulation;Female;Humans;Male;User-Computer Interface;Video Games;Young Adult\}, \
doi=\{10.1109/TVCG.2012.43\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165145, \
author=\{Cashion, J. and Wingrave, C. and LaViola, J.J.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Dense and Dynamic 3D Selection for Game-Based Virtual Environments\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{634-642\}, \
abstract=\{3D object selection is more demanding when, 1) objects densly surround the target object, 2) the target object is significantly occluded, and 3) when the target object is dynamically changing location. Most 3D selection techniques and guidelines were developed and tested on static or mostly sparse environments. In contrast, games tend to incorporate densly packed and dynamic objects as part of their typical interaction. With the increasing popularity of 3D selection in games using hand gestures or motion controllers, our current understanding of 3D selection needs revision. We present a study that compared four different selection techniques under five different scenarios based on varying object density and motion dynamics. We utilized two existing techniques, Raycasting and SQUAD, and developed two variations of them, Zoom and Expand, using iterative design. Our results indicate that while Raycasting and SQUAD both have weaknesses in terms of speed and accuracy in dense and dynamic environments, by making small modifications to them (i.e., flavoring), we can achieve significant performance increases.\}, \
keywords=\{computer games;iterative methods;user interfaces;virtual reality;3D selection guidelines;3D selection techniques;Raycasting technique;SQUAD technique;dense 3D object selection;dynamic 3D object selection;expand variation;game-based virtual environment;hand gesture;iterative design;motion controller;motion dynamics;object density;sparse environment;zoom variation;Accuracy;Color;Context;Games;Guidelines;Three dimensional displays;Usability;3D object selection;Interaction techniques;dense and dynamic objects.;game-based virtual environments;Adolescent;Adult;Computer Graphics;Computer Simulation;Environment;Female;Humans;Imaging, Three-Dimensional;Male;Motion;User-Computer Interface;Video Games;Young Adult\}, \
doi=\{10.1109/TVCG.2012.40\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165146, \
author=\{Jing Tong and Jin Zhou and Ligang Liu and Zhigeng Pan and Hao Yan\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Scanning 3D Full Human Bodies Using Kinects\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{643-650\}, \
abstract=\{Depth camera such as Microsoft Kinect, is much cheaper than conventional 3D scanning devices, and thus it can be acquired for everyday users easily. However, the depth data captured by Kinect over a certain distance is of extreme low quality. In this paper, we present a novel scanning system for capturing 3D full human body models by using multiple Kinects. To avoid the interference phenomena, we use two Kinects to capture the upper part and lower part of a human body respectively without overlapping region. A third Kinect is used to capture the middle part of the human body from the opposite direction. We propose a practical approach for registering the various body parts of different views under non-rigid deformation. First, a rough mesh template is constructed and used to deform successive frames pairwisely. Second, global alignment is performed to distribute errors in the deformation space, which can solve the loop closure problem efficiently. Misalignment caused by complex occlusion can also be handled reasonably by our global alignment algorithm. The experimental results have shown the efficiency and applicability of our system. Our system obtains impressive results in a few minutes with low price devices, thus is practically useful for generating personalized avatars for everyday users. Our system has been used for 3D human animation and virtual try on, and can further facilitate a range of home-oriented virtual reality (VR) applications.\}, \
keywords=\{avatars;computer animation;interactive devices;solid modelling;3D full human body model scanning;3D human animation;3D scanning devices;Microsoft Kinect;depth camera;error distribution;global alignment algorithm;home-oriented virtual reality applications;loop closure problem;nonrigid deformation;personalized avatars;rough mesh template;successive frame deformation;Biological system modeling;Computational modeling;Geometry;Humans;Image reconstruction;Shape;Three dimensional displays;3D Body Scanning;Microsoft Kinect;global non-igid registration;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional;Models, Anatomic;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2012.56\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6165147, \
author=\{Miller, A. and White, B. and Charbonneau, E. and Kanzler, Z. and LaViola, J.J.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Interactive 3D Model Acquisition and Tracking of Building Block Structures\}, \
year=\{2012\}, \
month=\{April\}, \
volume=\{18\}, \
number=\{4\}, \
pages=\{651-659\}, \
abstract=\{We present a prototype system for interactive construction and modification of 3D physical models using building blocks.Our system uses a depth sensing camera and a novel algorithm for acquiring and tracking the physical models. The algorithm,Lattice-First, is based on the fact that building block structures can be arranged in a 3D point lattice where the smallest block unit is a basis in which to derive all the pieces of the model. The algorithm also makes it possible for users to interact naturally with the physical model as it is acquired, using their bare hands to add and remove pieces. We present the details of our algorithm, along with examples of the models we can acquire using the interactive system. We also show the results of an experiment where participants modify a block structure in the absence of visual feedback. Finally, we discuss two proof-of-concept applications: a collaborative guided assembly system where one user is interactively guided to build a structure based on another user's design, and a game where the player must build a structure that matches an on-screen silhouette.\}, \
keywords=\{cameras;data acquisition;solid modelling;user interfaces;3D model acquisition;3D model tracking;3D physical model;3D point lattice;building block structure;collaborative guided assembly system;depth sensing camera;interactive 3D model;interactive construction;interactive modification;lattice-first algorithm;on-screen silhouette;user design;user interaction;visual feedback;Cameras;Computational modeling;Image color analysis;Lattices;Solid modeling;Three dimensional displays;Visualization;3D model acquisition;Interactive physical model building;building block structures.;depth cameras;object tracking;Algorithms;Computer Graphics;Computer Simulation;Humans;Imaging, Three-Dimensional;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2012.48\}, \
ISSN=\{1077-2626\},\}}