@ARTICLE{6051432, 
author={Oelke, D. and Spretke, D. and Stoffel, A. and Keim, D.A.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Visual Readability Analysis: How to Make Your Writings Easier to Read}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={662-674}, 
abstract={We present a tool that is specifically designed to support a writer in revising a draft version of a document. In addition to showing which paragraphs and sentences are difficult to read and understand, we assist the reader in understanding why this is the case. This requires features that are expressive predictors of readability, and are also semantically understandable. In the first part of the paper, we, therefore, discuss a semiautomatic feature selection approach that is used to choose appropriate measures from a collection of 141 candidate readability features. In the second part, we present the visual analysis tool VisRA, which allows the user to analyze the feature values across the text and within single sentences. Users can choose between different visual representations accounting for differences in the size of the documents and the availability of information about the physical and logical layout of the documents. We put special emphasis on providing as much transparency as possible to ensure that the user can purposefully improve the readability of a sentence. Several case studies are presented that show the wide range of applicability of our tool. Furthermore, an in-depth evaluation assesses the quality of the measure and investigates how well users do in revising a text with the help of the tool.}, 
keywords={learning (artificial intelligence);text analysis;VisRA;document processing;draft version;semiautomatic feature selection approach;text processing;visual analysis tool;visual readability analysis;visual representations;Correlation;Length measurement;Navigation;Training data;Visual analytics;Vocabulary;Document and text processing;feature evaluation and selection.;Books;Comprehension;Computer Graphics;Databases, Factual;Humans;Image Processing, Computer-Assisted;Linguistics;Reading;Software;Writing}, 
doi={10.1109/TVCG.2011.266}, 
ISSN={1077-2626},}
@ARTICLE{6018964, 
author={Andrienko, G. and Andrienko, N. and Mladenov, M. and Mock, M. and Politz, C.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Identifying Place Histories from Activity Traces with an Eye to Parameter Impact}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={675-688}, 
abstract={Events that happened in the past are important for understanding the ongoing processes, predicting future developments, and making informed decisions. Important and/or interesting events tend to attract many people. Some people leave traces of their attendance in the form of computer-processable data, such as records in the databases of mobile phone operators or photos on photo sharing web sites. We developed a suite of visual analytics methods for reconstructing past events from these activity traces. Our tools combine geocomputations, interactive geovisualizations, and statistical methods to enable integrated analysis of the spatial, temporal, and thematic components of the data, including numeric attributes and texts. We also support interactive investigation of the sensitivity of the analysis results to the parameters used in the computations. For this purpose, statistical summaries of computation results obtained with different combinations of parameter values are visualized in a way facilitating comparisons. We demonstrate the utility of our approach on two large real data sets, mobile phone calls in Milano during 9 days and flickr photos made on British Isles during 5 years.}, 
keywords={data visualisation;geography;history;mobile computing;statistical analysis;Flickr photos;activity traces;computer-processable data;database;eye;geocomputation;interactive geovisualization;interactive investigation;mobile phone operator;past event reconstruction;photo sharing Web sites;place history identification;spatial component;statistical method;statistical summary;temporal component;thematic component;visual analytics method;Area measurement;Data visualization;Databases;History;Time series analysis;Visual analytics;Keywords&#x2014;Event detection;geovisualization;scalable visualization;scale effect.;sensitivity analysis;spatiotemporal data;time series analysis;visual analytics;Activities of Daily Living;Cellular Phone;Computer Graphics;Data Interpretation, Statistical;Databases, Factual;Geography;Humans;Time}, 
doi={10.1109/TVCG.2011.153}, 
ISSN={1077-2626},}
@ARTICLE{6104042, 
author={Isenberg, P. and Fisher, D. and Paul, S.A. and Morris, M.R. and Inkpen, K. and Czerwinski, Mary}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Co-Located Collaborative Visual Analytics around a Tabletop Display}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={689-702}, 
abstract={Co-located collaboration can be extremely valuable during complex visual analytics tasks. We present an exploratory study of a system designed to support collaborative visual analysis tasks on a digital tabletop display. Fifteen participant pairs employed Cambiera, a visual analytics system, to solve a problem involving 240 digital documents. Our analysis, supported by observations, system logs, questionnaires, and interview data, explores how pairs approached the problem around the table. We contribute a unique, rich understanding of how users worked together around the table and identify eight types of collaboration styles that can be used to identify how closely people work together while problem solving. We show how the closeness of teams' collaboration and communication influenced how they performed on the task overall. We further discuss the role of the tabletop for visual analytics tasks and derive design implications for future co-located collaborative tabletop problem solving systems.}, 
keywords={computer displays;data analysis;data visualisation;groupware;problem solving;Cambiera system;collaboration style;colocated collaborative visual analytics;complex visual analytics task;digital tabletop display;interview data;observations;problem solving systems;questionnaires;system logs;team collaboration;team communication;Collaboration;Collaborative work;Context;Data visualization;Keyboards;Problem-solving;Visual analytics;Co-located collaboration;collaborative information visualization;complex problem solving.;tabletop displays}, 
doi={10.1109/TVCG.2011.287}, 
ISSN={1077-2626},}
@ARTICLE{5887329, 
author={Kexiang Wang and Xin Li and Bo Li and Huanhuan Xu and Hong Qin}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Restricted Trivariate Polycube Splines for Volumetric Data Modeling}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={703-716}, 
abstract={This paper presents a volumetric modeling framework to construct a novel spline scheme called restricted trivariate polycube splines (RTP-splines). The RTP-spline aims to generalize both trivariate T-splines and tensor-product B-splines; it uses solid polycube structure as underlying parametric domains and strictly bounds blending functions within such domains. We construct volumetric RTP-splines in a top-down fashion in four steps: 1) Extending the polycube domain to its bounding volume via space filling; 2) building the B-spline volume over the extended domain with restricted boundaries; 3) inserting duplicate knots by adding anchor points and performing local refinement; and 4) removing exterior cells and anchors. Besides local refinement inherited from general T-splines, the RTP-splines have a few attractive properties as follows: 1) They naturally model solid objects with complicated topologies/bifurcations using a one-piece continuous representation without domain trimming/patching/merging. 2) They have guaranteed semistandardness so that the functions and derivatives evaluation is very efficient. 3) Their restricted support regions of blending functions prevent control points from influencing other nearby domain regions that stay opposite to the immediate boundaries. These features are highly desirable for certain applications such as isogeometric analysis. We conduct extensive experiments on converting complicated solid models into RTP-splines, and demonstrate the proposed spline to be a powerful and promising tool for volumetric modeling and other scientific/engineering applications where data sets with multiattributes are prevalent.}, 
keywords={solid modelling;splines (mathematics);RTP-splines scheme;anchor points;anchors removal;blending function;bounding volume;domain merging;domain patching;domain trimming;exterior cell removal;isogeometric analysis;local refinement;one-piece continuous representation;parametric domain;polycube structure;restricted trivariate polycube splines scheme;space filling;strictly bounds blending function;tensor-product B-splines;trivariate T-splines;volumetric data modeling;Computational modeling;Solid modeling;Solids;Splines (mathematics);Surface reconstruction;Surface topography;Trivariate splines;polycube mapping.;polycube splines}, 
doi={10.1109/TVCG.2011.102}, 
ISSN={1077-2626},}
@ARTICLE{5887332, 
author={Fierz, B. and Spillmann, J. and Hoyos, I.A. and Harders, M.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Maintaining Large Time Steps in Explicit Finite Element Simulations Using Shape Matching}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={717-728}, 
abstract={We present a novel hybrid method to allow large time steps in explicit integrations for the simulation of deformable objects. In explicit integration schemes, the time step is typically limited by the size and the shape of the discretization elements as well as by the material parameters. We propose a two-step strategy to enable large time steps for meshes with elements potentially destabilizing the integration. First, the necessary time step for a stable computation is identified per element using modal analysis. This allows determining which elements have to be handled specially given a desired simulation time step. The identified critical elements are treated by a geometric deformation model, while the remaining ones are simulated with a standard deformation model (in our case, a corotational linear Finite Element Method). In order to achieve a valid deformation behavior, we propose a strategy to determine appropriate parameters for the geometric model. Our hybrid method allows taking much larger time steps than using an explicit Finite Element Method alone. The total computational costs per second are significantly lowered. The proposed scheme is especially useful for simulations requiring interactive mesh updates, such as for instance cutting in surgical simulations.}, 
keywords={computer animation;finite element analysis;pattern matching;corotational linear finite element method;deformable object simulation;deformation behavior;discretization element;explicit finite element simulation;explicit integration scheme;geometric deformation model;interactive mesh update;material parameter;modal analysis;shape matching;simulation time step;standard deformation model;surgical simulation;time step maintenance;Computational modeling;Deformable models;Estimation;Finite element methods;Mathematical model;Sockets;Solid modeling;Physically based modeling;real time;stability and instability.;virtual reality;Algorithms;Cluster Analysis;Computer Graphics;Computer Simulation;Elastic Modulus;Finite Element Analysis;Humans;Image Processing, Computer-Assisted;Liver;Models, Biological}, 
doi={10.1109/TVCG.2011.105}, 
ISSN={1077-2626},}
@ARTICLE{5728806, 
author={Min-Wen Chao and Chao-Hung Lin and Assa, J. and Tong-Yee Lee}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Human Motion Retrieval from Hand-Drawn Sketch}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={729-740}, 
abstract={The rapid growth of motion capture data increases the importance of motion retrieval. The majority of the existing motion retrieval approaches are based on a labor-intensive step in which the user browses and selects a desired query motion clip from the large motion clip database. In this work, a novel sketching interface for defining the query is presented. This simple approach allows users to define the required motion by sketching several motion strokes over a drawn character, which requires less effort and extends the users' expressiveness. To support the real-time interface, a specialized encoding of the motions and the hand-drawn query is required. Here, we introduce a novel hierarchical encoding scheme based on a set of orthonormal spherical harmonic (SH) basis functions, which provides a compact representation, and avoids the CPU/processing intensive stage of temporal alignment used by previous solutions. Experimental results show that the proposed approach can well retrieve the motions, and is capable of retrieve logically and numerically similar motions, which is superior to previous approaches. The user study shows that the proposed system can be a useful tool to input motion query if the users are familiar with it. Finally, an application of generating a 3D animation from a hand-drawn comics strip is demonstrated.}, 
keywords={computer animation;database management systems;query processing;user interfaces;3D animation;drawn character;hand-drawn comics strip;hand-drawn query;hand-drawn sketch;hierarchical encoding scheme;human motion retrieval;motion capture data;motion clip database;motion encoding;orthonormal spherical harmonic basis function;query definition;query motion clip;sketching interface;temporal alignment stage;user browsing;user expressiveness;user selection;Databases;Ellipsoids;Encoding;Harmonic analysis;Joints;Three dimensional displays;Trajectory;Motion retrieval;sketching interface.;spherical harmonic function;Art;Computer Graphics;Humans;Imaging, Three-Dimensional;Information Storage and Retrieval;Movement}, 
doi={10.1109/TVCG.2011.53}, 
ISSN={1077-2626},}
@ARTICLE{5669299, 
author={Shum, H.P.H. and Komura, T. and Yamazaki, S.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Simulating Multiple Character Interactions with Collaborative and Adversarial Goals}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={741-752}, 
abstract={This paper proposes a new methodology for synthesizing animations of multiple characters, allowing them to intelligently compete with one another in dense environments, while still satisfying requirements set by an animator. To achieve these two conflicting objectives simultaneously, our method separately evaluates the competition and collaboration of the interactions, integrating the scores to select an action that maximizes both criteria. We extend the idea of min-max search, normally used for strategic games such as chess. Using our method, animators can efficiently produce scenes of dense character interactions such as those in collective sports or martial arts. The method is especially effective for producing animations along story lines, where the characters must follow multiple objectives, while still accommodating geometric and kinematic constraints from the environment.}, 
keywords={computer animation;minimax techniques;search problems;adversarial goal;animation production;collaborative goal;collective sports;dense character interaction;geometric constraint;interaction collaboration;interaction competition;kinematic constraint;martial arts;min-max search;multiple character animation synthesis;multiple character interaction simulation;strategic game;Animation;Computational modeling;Electronic mail;Equations;Games;Motion segmentation;Optimization;Character animation;character interaction.}, 
doi={10.1109/TVCG.2010.257}, 
ISSN={1077-2626},}
@ARTICLE{5887330, 
author={Martin, T. and Cohen, E. and Kirby, R.M.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Direct Isosurface Visualization of Hex-Based High-Order Geometry and Attribute Representations}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={753-766}, 
abstract={In this paper, we present a novel isosurface visualization technique that guarantees the accurate visualization of isosurfaces with complex attribute data defined on (un)structured (curvi)linear hexahedral grids. Isosurfaces of high-order hexahedral-based finite element solutions on both uniform grids (including MRI and CT scans) and more complex geometry representing a domain of interest that can be rendered using our algorithm. Additionally, our technique can be used to directly visualize solutions and attributes in isogeometric analysis, an area based on trivariate high-order NURBS (Non-Uniform Rational B-splines) geometry and attribute representations for the analysis. Furthermore, our technique can be used to visualize isosurfaces of algebraic functions. Our approach combines subdivision and numerical root finding to form a robust and efficient isosurface visualization algorithm that does not miss surface features, while finding all intersections between a view frustum and desired isosurfaces. This allows the use of view-independent transparency in the rendering process. We demonstrate our technique through a straightforward CPU implementation on both complex-structured and complex-unstructured geometries with high-order simulation solutions, isosurfaces of medical data sets, and isosurfaces of algebraic functions.}, 
keywords={computational geometry;data visualisation;finite element analysis;rendering (computer graphics);splines (mathematics);algebraic function;attribute representation;complex-structured geometry;complex-unstructured geometry;direct isosurface visualization technique;hex-based high-order geometry;high-order hexahedral-based finite element solution;high-order simulation solution;isogeometric analysis;medical data set;nonuniform rational B-splines geometry;rendering process;trivariate high-order NURBS geometry;unstructured curvilinear hexahedral grids;view-independent transparency;Isosurfaces;Pixel;Splines (mathematics);Surface reconstruction;Surface topography;Isosurface visualization of hex-based high-order geometry and attribute representations;numerical analysis;roots of nonlinear equations;spline and piecewise polynomial interpolation.}, 
doi={10.1109/TVCG.2011.103}, 
ISSN={1077-2626},}
@ARTICLE{5928334, 
author={Guoning Chen and Qingqing Deng and Szymczak, A. and Laramee, R.S. and Zhang, E.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Morse Set Classification and Hierarchical Refinement Using Conley Index}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={767-782}, 
abstract={Morse decomposition provides a numerically stable topological representation of vector fields that is crucial for their rigorous interpretation. However, Morse decomposition is not unique, and its granularity directly impacts its computational cost. In this paper, we propose an automatic refinement scheme to construct the Morse Connection Graph (MCG) of a given vector field in a hierarchical fashion. Our framework allows a Morse set to be refined through a local update of the flow combinatorialization graph, as well as the connection regions between Morse sets. The computation is fast because the most expensive computation is concentrated on a small portion of the domain. Furthermore, the present work allows the generation of a topologically consistent hierarchy of MCGs, which cannot be obtained using a global method. The classification of the extracted Morse sets is a crucial step for the construction of the MCG, for which the Poincaré index is inadequate. We make use of an upper bound for the Conley index, provided by the Betti numbers of an index pair for a translation along the flow, to classify the Morse sets. This upper bound is sufficiently accurate for Morse set classification and provides supportive information for the automatic refinement process. An improved visualization technique for MCG is developed to incorporate the Conley indices. Finally, we apply the proposed techniques to a number of synthetic and real-world simulation data to demonstrate their utility.}, 
keywords={data visualisation;graph theory;mathematics computing;numerical stability;pattern classification;set theory;topology;vectors;Betti numbers;Conley index;Morse connection graph;Morse decomposition;Morse set classification;Poincare index;flow combinatorialization graph;hierarchical refinement;numerically stable topological representation;real-world simulation data;synthetic data;vector field;visualization technique;Approximation methods;Electrocardiography;Indexes;Orbits;Topology;Trajectory;Upper bound;Morse decomposition;hierarchical refinement.;topology refinement;upper bound of Conley index;vector field topology}, 
doi={10.1109/TVCG.2011.107}, 
ISSN={1077-2626},}
@ARTICLE{5928336, 
author={Zhanping Liu and Shangshu Cai and Swan, J.E. and Moorhead, R.J. and Martin, J.P. and Jankun-Kelly, T. J.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={A 2D Flow Visualization User Study Using Explicit Flow Synthesis and Implicit Task Design}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={783-796}, 
abstract={This paper presents a 2D flow visualization user study that we conducted using new methodologies to increase the objectiveness. We evaluated grid-based variable-size arrows, evenly spaced streamlines, and line integral convolution (LIC) variants (basic, oriented, and enhanced versions) coupled with a colorwheel and/or rainbow color map, which are representative of many geometry-based and texture-based techniques. To reduce data-related bias, template-based explicit flow synthesis was used to create a wide variety of symmetric flows with similar topological complexity. To suppress task-related bias, pattern-based implicit task design was employed, addressing critical point recognition, critical point classification, and symmetric pattern categorization. In addition, variable-duration and fixed-duration measurement schemes were utilized for lightweight precision-critical and heavyweight judgment-intensive flow analysis tasks, respectively, to record visualization effectiveness. We eliminated outliers and used the Ryan REGWQ post-hoc homogeneous subset tests in statistical analysis to obtain reliable findings. Our study shows that a texture-based dense representation with accentuated flow streaks, such as enhanced LIC, enables intuitive perception of the flow, while a geometry-based integral representation with uniform density control, such as evenly spaced streamlines, may exploit visual interpolation to facilitate mental reconstruction of the flow. It is also shown that inappropriate color mapping (e.g., colorwheel) may add distractions to a flow representation.}, 
keywords={data visualisation;interpolation;pattern classification;statistical analysis;user interfaces;2D flow visualization user study;Ryan REGWQ post-hoc homogeneous subset test;colorwheel map;critical point classification;critical point recognition;data-related bias reduction;explicit flow synthesis;fixed-duration measurement scheme;flow mental reconstruction;flow representation;geometry-based integral representation;geometry-based techniques;grid-based variable-size arrow;heavyweight judgment-intensive flow analysis task;lightweight precision-critical flow analysis task;line integral convolution variant;outliers;pattern-based implicit task design;rainbow color map;statistical analysis;streamlines variant;symmetric pattern categorization;texture-based dense representation;texture-based techniques;topological complexity;variable-duration measurement scheme;visual interpolation;visualization effectiveness;Color;Electronic mail;Force;Image color analysis;Streaming media;Synthesizers;Visualization;Index Terms&#x2014;Flow visualization;LIC;evenly spaced streamlines.;flow synthesis;task design;test strategy;user study;visualization effectiveness}, 
doi={10.1109/TVCG.2011.110}, 
ISSN={1077-2626},}
@ARTICLE{5887326, 
author={Pak Chung Wong and Foote, H. and Mackey, P. and Chin, G. and Zhenyu Huang and Thomas, J.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={A Space-Filling Visualization Technique for Multivariate Small-World Graphs}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={797-809}, 
abstract={We introduce an information visualization technique, known as GreenCurve, for large multivariate sparse graphs that exhibit small-world properties. Our fractal-based design approach uses spatial cues to approximate the node connections and thus eliminates the links between the nodes in the visualization. The paper describes a robust algorithm to order the neighboring nodes of a large sparse graph by solving the Fiedler vector of its graph Laplacian, and then fold the graph nodes into a space-filling fractal curve based on the Fiedler vector. The result is a highly compact visualization that gives a succinct overview of the graph with guaranteed visibility of every graph node. GreenCurve is designed with the power grid infrastructure in mind. It is intended for use in conjunction with other visualization techniques to support electric power grid operations. The research and development of GreenCurve was conducted in collaboration with domain experts who understand the challenges and possibilities intrinsic to the power grid infrastructure. The paper reports a case study on applying GreenCurve to a power grid problem and presents a usability study to evaluate the design claims that we set forth.}, 
keywords={curve fitting;data visualisation;graph theory;power engineering computing;power grids;vectors;Fiedler vector;GreenCurve technique;Laplacian graph;domain expert;electric power grid operation;fractal-based design approach;multivariate small-world graphs;multivariate sparse graph;node connection;power grid infrastructure;power grid problem;small-world property;space-filling fractal curve;space-filling visualization technique;spatial cue;usability study;visualization node;Data visualization;Fractals;Laplace equations;Layout;Partitioning algorithms;Power grids;Sparse matrices;Data and knowledge visualization;information visualization;visualization techniques and methodologies.}, 
doi={10.1109/TVCG.2011.99}, 
ISSN={1077-2626},}
@ARTICLE{5887331, 
author={Sheng-Jie Luo and Chun-Liang Liu and Bing-Yu Chen and Kwan-Liu Ma}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Ambiguity-Free Edge-Bundling for Interactive Graph Visualization}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={810-821}, 
abstract={Graph visualization has been widely used to understand and present both global structural and local adjacency information in relational data sets (e.g., transportation networks, citation networks, or social networks). Graphs with dense edges, however, are difficult to visualize because fast layout and good clarity are not always easily achieved. When the number of edges is large, edge bundling can be used to improve the clarity, but in many cases, the edges could be still too cluttered to permit correct interpretation of the relations between nodes. In this paper, we present an ambiguity-free edge-bundling method especially for improving local detailed view of a complex graph. Our method makes more efficient use of display space and supports detail-on-demand viewing through an interactive interface. We demonstrate the effectiveness of our method with public coauthorship network data.}, 
keywords={data visualisation;graph theory;ambiguity-free edge-bundling method;citation network;complex graph;dense graph edge;detail-on-demand viewing;display space;global structural adjacency information;interactive graph visualization;interactive interface;local adjacency information;public coauthorship network data;relational data set;social network;transportation network;Clutter;Data visualization;Image edge detection;Layout;Routing;Social network services;Visualization;Graph visualization;detail-on-demand;edge ambiguity;edge bundling;edge congestion;interactive navigation.;network visualization}, 
doi={10.1109/TVCG.2011.104}, 
ISSN={1077-2626},}
@ARTICLE{5928333, 
author={Spritzer, A.S. and Dal Sasso Freitas, C.M.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Design and Evaluation of MagnetViz-A Graph Visualization Tool}, 
year={2012}, 
month={May}, 
volume={18}, 
number={5}, 
pages={822-835}, 
abstract={MagnetViz was designed for the interactive manipulation of force-directed graph layouts, allowing the user to obtain visualizations based on the graph topology and/or the attributes of its nodes and edges. The user can introduce virtual magnets anywhere in the graph and these can be set to attract nodes and edges that fulfill user-defined criteria. When a magnet is placed, the force-directed nature of the layout forces it to reorganize itself in order to reflect the changes in the balance of forces, consequently changing the visualization into one that is more semantically relevant to the user. This paper describes MagnetViz's concepts, illustrating them with examples and a case study based on a usage scenario. We also describe how the MagnetViz has evolved since its original version and present the evaluation of its latest version. This evaluation consists of two user studies aiming at assessing generated layout quality and how well the concepts can be apprehended and employed, and a task taxonomy assessment focusing on establishing which graph visualization tasks the technique is able to handle.}, 
keywords={data visualisation;directed graphs;user interfaces;MagnetViz tool;force balance;force-directed graph layout;generated layout quality;graph edge;graph node;graph topology;graph visualization tool;layout force;task taxonomy assessment;usage scenario;user studies;user-defined criteria;virtual magnet;Color;Data visualization;Layout;Magnetic separation;Shape;Topology;Visualization;Graph visualization;evaluation;force-directed layout;social networks visualization.}, 
doi={10.1109/TVCG.2011.106}, 
ISSN={1077-2626},}