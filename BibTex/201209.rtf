{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf190
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs24 \cf0 @ARTICLE\{6051431, \
author=\{Bhatia, H. and Jadhav, S. and Bremer, P. and Guoning Chen and Levine, J.A. and Nonato, L.G. and Pascucci, V.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Flow Visualization with Quantified Spatial and Temporal Errors Using Edge Maps\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1383-1396\}, \
abstract=\{Robust analysis of vector fields has been established as an important tool for deriving insights from the complex systems these fields model. Traditional analysis and visualization techniques rely primarily on computing streamlines through numerical integration. The inherent numerical errors of such approaches are usually ignored, leading to inconsistencies that cause unreliable visualizations and can ultimately prevent in-depth analysis. We propose a new representation for vector fields on surfaces that replaces numerical integration through triangles with maps from the triangle boundaries to themselves. This representation, called edge maps, permits a concise description of flow behaviors and is equivalent to computing all possible streamlines at a user defined error threshold. Independent of this error streamlines computed using edge maps are guaranteed to be consistent up to floating point precision, enabling the stable extraction of features such as the topological skeleton. Furthermore, our representation explicitly stores spatial and temporal errors which we use to produce more informative visualizations. This work describes the construction of edge maps, the error quantification, and a refinement procedure to adhere to a user defined error bound. Finally, we introduce new visualizations using the additional information provided by edge maps to indicate the uncertainty involved in computing streamlines and topological structures.\}, \
keywords=\{error analysis;feature extraction;flow visualisation;topology;vectors;complex systems;edge maps;error quantification;error streamlines;error threshold;explicit storage;feature extraction;floating point precision;flow behaviors;flow visualization unreliability;numerical errors;quantified spatial error;quantified temporal error;refinement procedure;robust analysis;topological skeleton;triangle boundaries;user-defined error bound;vector fields;Data visualization;Image edge detection;Linear approximation;Skeleton;Uncertainty;Visualization;Vector fields;edge maps.;error quantification\}, \
doi=\{10.1109/TVCG.2011.265\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6171180, \
author=\{Hanqi Guo and He Xiao and Xiaoru Yuan\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Scalable Multivariate Volume Visualization and Analysis Based on Dimension Projection and Parallel Coordinates\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1397-1410\}, \
abstract=\{In this paper, we present an effective and scalable system for multivariate volume data visualization and analysis with a novel transfer function interface design that tightly couples parallel coordinates plots (PCP) and MDS-based dimension projection plots. In our system, the PCP visualizes the data distribution of each variate (dimension) and the MDS plots project features. They are integrated seamlessly to provide flexible feature classification without context switching between different data presentations during the user interaction. The proposed interface enables users to identify relevant correlation clusters and assign optical properties with lassos, magic wand, and other tools. Furthermore, direct sketching on the volume rendered images has been implemented to probe and edit features. With our system, users can interactively analyze multivariate volumetric data sets by navigating and exploring feature spaces in unified PCP and MDS plots. To further support large-scale multivariate volume data visualization and analysis, Scalable Pivot MDS (SPMDS), parallel adaptive continuous PCP rendering, as well as parallel rendering techniques are developed and integrated into our visualization system. Our experiments show that the system is effective in multivariate volume data visualization and its performance is highly scalable for data sets with different sizes and number of variates.\}, \
keywords=\{data visualisation;pattern classification;rendering (computer graphics);MDS plots;MDS-based dimension projection plots;PCP plots;context switching;data presentations;dimension projection;direct sketching;flexible feature classification;lassos;magic wand;multivariate volume data visualization;multivariate volumetric data sets;optical properties;parallel adaptive continuous PCP rendering;parallel coordinates;parallel coordinates plots;scalable multivariate volume visualization;scalable pivot MDS;transfer function interface design;user interaction;volume rendered images;Algorithm design and analysis;Correlation;Data visualization;Rendering (computer graphics);Transfer functions;Vegetation;Multivariate volume;dimension projection;parallel coordinates;parallel visualization.;transfer function;user-interface design\}, \
doi=\{10.1109/TVCG.2012.80\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6175895, \
author=\{Riehmann, P. and Gruendl, H. and Potthast, M. and Trenkmann, M. and Stein, B. and Froehlich, B.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{WORDGRAPH: Keyword-in-Context Visualization for NETSPEAK's Wildcard Search\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1411-1423\}, \
abstract=\{The WORDGRAPH helps writers in visually choosing phrases while writing a text. It checks for the commonness of phrases and allows for the retrieval of alternatives by means of wildcard queries. To support such queries, we implement a scalable retrieval engine, which returns high-quality results within milliseconds using a probabilistic retrieval strategy. The results are displayed as WORDGRAPH visualization or as a textual list. The graphical interface provides an effective means for interactive exploration of search results using filter techniques, query expansion, and navigation. Our observations indicate that, of three investigated retrieval tasks, the textual interface is sufficient for the phrase verification task, wherein both interfaces support context-sensitive word choice, and the WORDGRAPH best supports the exploration of a phrase's context or the underlying corpus. Our user study confirms these observations and shows that WORDGRAPH is generally the preferred interface over the textual result list for queries containing multiple wildcards.\}, \
keywords=\{data visualisation;information retrieval;probability;NETSPEAK wildcard search;WORDGRAPH;filter techniques;graphical interface;interactive exploration;keyword-in-context visualization;phrase context;probabilistic retrieval strategy;query expansion;query navigation;scalable retrieval engine;underlying corpus;visually choosing phrases;wildcard queries;Engines;Google;Indexes;Layout;Navigation;Visualization;Information visualization;Web n-grams;information retrieval;text visualization;visual queries;wildcard search.\}, \
doi=\{10.1109/TVCG.2012.96\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6109250, \
author=\{Mashima, D. and Kobourov, S.G. and Yifan Hu\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Visualizing Dynamic Data with Maps\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1424-1437\}, \
abstract=\{Maps offer a familiar way to present geographic data (continents, countries), and additional information (topography, geology), can be displayed with the help of contours and heat-map overlays. In this paper, we consider visualizing large-scale dynamic relational data by taking advantage of the geographic map metaphor. We describe a map-based visualization system which uses animation to convey dynamics in large data sets, and which aims to preserve the viewer's mental map while also offering readable views at all times. Our system is fully functional and has been used to visualize user traffic on the Internet radio station last.fm, as well as TV-viewing patterns from an IPTV service. All map images in this paper are available in high-resolution at [CHECK END OF SENTENCE] as are several movies illustrating the dynamic visualization.\}, \
keywords=\{data visualisation;dynamic programming;geographic information systems;IPTV service;Internet radio station;TV-viewing patterns;dynamic data visualisation;geographic data;geographic map metaphor;heat map overlays;large scale dynamic relational data;map based visualization system;maps;Animation;Clustering algorithms;Data mining;Data visualization;Heuristic algorithms;Layout;Measurement;Information interface and presentation;dynamic visualization;graph drawing;map-based visualization.;multimedia information systems;spatialization\}, \
doi=\{10.1109/TVCG.2011.288\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6081859, \
author=\{Benthin, C. and Wald, I. and Woop, S. and Ernst, M. and Mark, W.R.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Combining Single and Packet-Ray Tracing for Arbitrary Ray Distributions on the Intel MIC Architecture\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1438-1448\}, \
abstract=\{Wide-SIMD hardware is power and area efficient, but it is challenging to efficiently map ray tracing algorithms to such hardware especially when the rays are incoherent. The two most commonly used schemes are either packet tracing, or relying on a separate traversal stack for each SIMD lane. Both work great for coherent rays, but suffer when rays are incoherent: The former experiences a dramatic loss of SIMD utilization once rays diverge; the latter requires a large local storage, and generates multiple incoherent streams of memory accesses that present challenges for the memory system. In this paper, we introduce a single-ray tracing scheme for incoherent rays that uses just one traversal stack on 16-wide SIMD hardware. It uses a bounding-volume hierarchy with a branching factor of four as the acceleration structure, exploits four-wide SIMD in each box and primitive intersection test, and uses 16-wide SIMD by always performing four such node or primitive tests in parallel. We then extend this scheme to a hybrid tracing scheme that automatically adapts to varying ray coherence by starting out with a 16-wide packet scheme and switching to the new single-ray scheme as soon as rays diverge. We show that on the Intel Many Integrated Core architecture this hybrid scheme consistently, and over a wide range of scenes and ray distributions, outperforms both packet and single-ray tracing.\}, \
keywords=\{multiprocessing systems;parallel architectures;ray tracing;16-wide SIMD hardware;Intel MIC architecture;Intel many integrated core architecture;SIMD lane;SIMD utilization;arbitrary ray distributions;bounding-volume hierarchy;branching factor;hybrid tracing scheme;memory accesses;multiple incoherent streams;packet-ray tracing;primitive intersection test;single-ray tracing scheme;traversal stack;Hardware;Kernel;Memory management;Ray tracing;Registers;Vectors;Ray tracing;SIMD processors.\}, \
doi=\{10.1109/TVCG.2011.277\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6025351, \
author=\{Youngmin Park and Lepetit, V. and Woontack Woo\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Handling Motion-Blur in 3D Tracking and Rendering for Augmented Reality\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1449-1459\}, \
abstract=\{The contribution of this paper is two-fold. First, we show how to extend the ESM algorithm to handle motion blur in 3D object tracking. ESM is a powerful algorithm for template matching-based tracking, but it can fail under motion blur. We introduce an image formation model that explicitly consider the possibility of blur, and shows its results in a generalization of the original ESM algorithm. This allows to converge faster, more accurately and more robustly even under large amount of blur. Our second contribution is an efficient method for rendering the virtual objects under the estimated motion blur. It renders two images of the object under 3D perspective, and warps them to create many intermediate images. By fusing these images we obtain a final image for the virtual objects blurred consistently with the captured image. Because warping is much faster than 3D rendering, we can create realistically blurred images at a very low computational cost.\}, \
keywords=\{augmented reality;image matching;image motion analysis;image restoration;object tracking;rendering (computer graphics);solid modelling;3D object tracking;3D rendering;ESM algorithm;augmented reality;image formation model;image fusion;intermediate images;motion-blur;template matching-based tracking;virtual objects;Cameras;Computational modeling;Jacobian matrices;Rendering (computer graphics);Robustness;Three dimensional displays;Tracking;Augmented reality;computer vision;efficient second-order minimization.;motion-blur;object detection;object tracking\}, \
doi=\{10.1109/TVCG.2011.158\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6081858, \
author=\{Zagorchev, L.G. and Goshtasby, A.A.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{A Curvature-Adaptive Implicit Surface Reconstruction for Irregularly Spaced Points\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1460-1473\}, \
abstract=\{A curvature-adaptive implicit surface reconstruction for noisy and irregularly spaced points in 3D is introduced. The reconstructed surface traces the zero crossings of a signed field obtained from the sum of first-derivative anisotropic Gaussians centered at the points. The standard deviations of the anisotropic Gaussians are adapted to surface curvatures estimated from local data. A key characteristic of the formulation is its ability to smooth more along edges than across them, thereby preserving shape details while smoothing noise. The behavior of the proposed method under various density and organization of points is investigated and surface reconstruction results are compared with those obtained by well-known methods in the literature.\}, \
keywords=\{Gaussian processes;smoothing methods;solid modelling;3D surface reconstruction;computer graphics;curvature-adaptive implicit surface reconstruction;first-derivative anisotropic Gaussians;irregularly spaced points;local data;noise smoothing;noisy spaced points;shape details preservation;signed field zero crossings;standard deviations;surface curvatures;Image reconstruction;Rough surfaces;Shape;Smoothing methods;Surface reconstruction;Surface roughness;Surface treatment;Computer graphics;implicit surface;point cloud;smoothness parameter.;surface reconstruction\}, \
doi=\{10.1109/TVCG.2011.276\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6035703, \
author=\{Okaniwa, S. and Nasri, A. and Hongwei Lin and Abbas, A. and Kineri, Y. and Maekawa, T.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Uniform B-Spline Curve Interpolation with Prescribed Tangent and Curvature Vectors\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1474-1487\}, \
abstract=\{This paper presents a geometric algorithm for the generation of uniform cubic B-spline curves interpolating a sequence of data points under tangent and curvature vectors constraints. To satisfy these constraints, knot insertion is used to generate additional control points which are progressively repositioned using corresponding geometric rules. Compared to existing schemes, our approach is capable of handling plane as well as space curves, has local control, and avoids the solution of the typical linear system. The effectiveness of the proposed algorithm is illustrated through several comparative examples. Applications of the method in NC machining and shape design are also outlined.\}, \
keywords=\{computational geometry;interpolation;splines (mathematics);NC machining;curvature vectors;curvature vectors constraints;data point sequence;geometric algorithm;handling plane;knot insertion;linear system;prescribed tangent;shape design;space curves;uniform B-spline curve interpolation;Aerospace electronics;Educational institutions;Electronic mail;Equations;Interpolation;Spline;Vectors;B-spline curve;curvature vector;interpolation;parametric curve.;tangent\}, \
doi=\{10.1109/TVCG.2011.262\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6042858, \
author=\{Doyub Kim and Seung Woo Lee and Oh-young Song and Hyeong-Seok Ko\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Baroclinic Turbulence with Varying Density and Temperature\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1488-1495\}, \
abstract=\{The explosive or volcanic scenes in motion pictures involve complex turbulent flow as its temperature and density vary in space. To simulate this turbulent flow of an inhomogeneous fluid, we propose a simple and efficient framework. Instead of explicitly computing the complex motion of this fluid dynamical instability, we first approximate the average motion of the fluid. Then, the high-resolution dynamics is computed using our new extended version of the vortex particle method with baroclinity. This baroclinity term makes turbulent effects by generating new vortex particles according to temperature/density distributions. Using our method, we efficiently simulated a complex scene with varying density and temperature.\}, \
keywords=\{computational fluid dynamics;computer animation;flow instability;turbulence;vortices;baroclinic turbulence;baroclinity term;complex motion;complex turbulent flow;fluid dynamical instability;high-resolution dynamics;inhomogeneous fluid;motion pictures;turbulent effects;varying density;varying temperature;volcanic scenes;vortex particle;vortex particles;Computational modeling;Computer graphics;Equations;Force;Heating;Mathematical model;Nonhomogeneous media;Fluid animation;turbulent flow;variable density;vortex particle method.\}, \
doi=\{10.1109/TVCG.2011.264\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6065732, \
author=\{I-Cheng Yeh and Wen-Chieh Lin and Tong-Yee Lee and Hsin-Ju Han and Jehee Lee and Manmyung Kim\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Social-Event-Driven Camera Control for Multicharacter Animations\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1496-1510\}, \
abstract=\{In a virtual world, a group of virtual characters can interact with each other, and these characters may leave a group to join another. The interaction among individuals and groups often produces interesting events in a sequence of animation. The goal of this paper is to discover social events involving mutual interactions or group activities in multicharacter animations and automatically plan a smooth camera motion to view interesting events suggested by our system or relevant events specified by a user. Inspired by sociology studies, we borrow the knowledge in Proxemics, social force, and social network analysis to model the dynamic relation among social events and the relation among the participants within each event. By analyzing the variation of relation strength among participants and spatiotemporal correlation among events, we discover salient social events in a motion clip and generate an overview video of these events with smooth camera motion using a simulated annealing optimization method. We tested our approach on different motions performed by multiple characters. Our user study shows that our results are preferred in 66.19 percent of the comparisons with those by the camera control approach without event analysis and are comparable (51.79 percent) to professional results by an artist.\}, \
keywords=\{cameras;computer animation;virtual reality;Proxemics;group activities;motion clip;multicharacter animations;mutual interactions;simulated annealing optimization method;smooth camera motion;social event driven camera control;social events;social force;social network analysis;spatiotemporal correlation;virtual characters;virtual world;Animation;Atmospheric measurements;Cameras;Force;Particle measurements;Social network services;Trajectory;MOCAP;event analysis;multicharacter animation;social network analysis.\}, \
doi=\{10.1109/TVCG.2011.273\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6025350, \
author=\{Asthana, A. and de la Hunty, M. and Dhall, A. and Goecke, R.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Facial Performance Transfer via Deformable Models and Parametric Correspondence\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1511-1519\}, \
abstract=\{The issue of transferring facial performance from one person's face to another's has been an area of interest for the movie industry and the computer graphics community for quite some time. In recent years, deformable face models, such as the Active Appearance Model (AAM), have made it possible to track and synthesize faces in real time. Not surprisingly, deformable face model-based approaches for facial performance transfer have gained tremendous interest in the computer vision and graphics community. In this paper, we focus on the problem of real-time facial performance transfer using the AAM framework. We propose a novel approach of learning the mapping between the parameters of two completely independent AAMs, using them to facilitate the facial performance transfer in a more realistic manner than previous approaches. The main advantage of modeling this parametric correspondence is that it allows a "meaningful\'94 transfer of both the nonrigid shape and texture across faces irrespective of the speakers' gender, shape, and size of the faces, and illumination conditions. We explore linear and nonlinear methods for modeling the parametric correspondence between the AAMs and show that the sparse linear regression method performs the best. Moreover, we show the utility of the proposed framework for a cross-language facial performance transfer that is an area of interest for the movie dubbing industry.\}, \
keywords=\{cinematography;image texture;regression analysis;solid modelling;active appearance model;computer graphics community;computer vision;cross-language facial performance transfer;deformable face model-based approaches;movie dubbing industry;nonrigid shape;nonrigid texture;parametric correspondence;sparse linear regression method;Active appearance model;Computational modeling;Deformable models;Face;Shape;Solid modeling;Training;Active appearance models;face modeling and animation.;facial performance transfer\}, \
doi=\{10.1109/TVCG.2011.157\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6095544, \
author=\{Lam, H. and Bertini, E. and Isenberg, P. and Plaisant, C. and Carpendale, S.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Empirical Studies in Information Visualization: Seven Scenarios\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1520-1536\}, \
abstract=\{We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.\}, \
keywords=\{data visualisation;empirical studies;evaluating collaborative data analysis;evaluating communication;evaluating environments;evaluating user experience;evaluating visualization algorithms;information visualization;seven scenarios;user performance evaluation;visual data analysis;visual data reasoning;visualization publications;Data analysis;Data visualization;Electronic mail;Encoding;Systematics;Taxonomy;Visualization;Information visualization;evaluation.\}, \
doi=\{10.1109/TVCG.2011.279\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6060816, \
author=\{Rosen, P. and Popescu, V.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Simplification of Node Position Data ;for Interactive Visualization of Dynamic Data Sets\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1537-1548\}, \
abstract=\{We propose to aid the interactive visualization of time-varying spatial data sets by simplifying node position data over the entire simulation as opposed to over individual states. Our approach is based on two observations. The first observation is that the trajectory of some nodes can be approximated well without recording the position of the node for every state. The second observation is that there are groups of nodes whose motion from one state to the next can be approximated well with a single transformation. We present data set simplification techniques that take advantage of this node data redundancy. Our techniques are general, supporting many types of simulations, they achieve good compression factors, and they allow rigorous control of the maximum node position approximation error. We demonstrate our approach in the context of finite element analysis data, of liquid flow simulation data, and of fusion simulation data.\}, \
keywords=\{approximation theory;data visualisation;finite element analysis;interactive systems;data set simplification techniques;dynamic data sets;finite element analysis data;good compression factors;interactive visualization;maximum node position approximation error;node data redundancy;node position data;time-varying spatial data sets;Approximation methods;Clustering algorithms;Computational modeling;Data models;Data visualization;Encoding;Trajectory;Simplification of node positions;interactive visualization;rigid body decomposition;simulation data compression.;trajectory clustering;trajectory simplification\}, \
doi=\{10.1109/TVCG.2011.268\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6065731, \
author=\{Gyulassy, A. and Kotava, N. and Kim, M. and Hansen, C.D. and Hagen, H. and Pascucci, V.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Direct Feature Visualization Using Morse-Smale Complexes\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1549-1562\}, \
abstract=\{In this paper, we characterize the range of features that can be extracted from an Morse-Smale complex and describe a unified query language to extract them. We provide a visual dictionary to guide users when defining features in terms of these queries. We demonstrate our topology-rich visualization pipeline in a tool that interactively queries the MS complex to extract features at multiple resolutions, assigns rendering attributes, and combines traditional volume visualization with the extracted features. The flexibility and power of this approach is illustrated with examples showing novel features.\}, \
keywords=\{data visualisation;dictionaries;query languages;rendering (computer graphics);MS complex;Morse-Smale complexes;direct feature visualization;rendering attributes;topology-rich visualization pipeline;traditional volume visualization;unified query language;visual dictionary;Data structures;Data visualization;Feature extraction;Geometry;Manifolds;Vectors;Visualization;Volume visualization;applications;feature detection;topology.\}, \
doi=\{10.1109/TVCG.2011.272\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6060947, \
author=\{Reininghaus, J. and Kasten, J. and Weinkauf, T. and Hotz, I.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Efficient Computation of Combinatorial Feature Flow Fields\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1563-1573\}, \
abstract=\{We propose a combinatorial algorithm to track critical points of 2D time-dependent scalar fields. Existing tracking algorithms such as Feature Flow Fields apply numerical schemes utilizing derivatives of the data, which makes them prone to noise and involve a large number of computational parameters. In contrast, our method is robust against noise since it does not require derivatives, interpolation, and numerical integration. Furthermore, we propose an importance measure that combines the spatial persistence of a critical point with its temporal evolution. This leads to a time-aware feature hierarchy, which allows us to discriminate important from spurious features. Our method requires only a single, easy-to-tune computational parameter and is naturally formulated in an out-of-core fashion, which enables the analysis of large data sets. We apply our method to synthetic data and data sets from computational fluid dynamics and compare it to the stabilized continuous Feature Flow Field tracking algorithm.\}, \
keywords=\{combinatorial mathematics;computational fluid dynamics;flow visualisation;numerical analysis;2D time-dependent scalar fields;combinatorial algorithm;combinatorial feature flow field computation;computational fluid dynamics;computational parameters;critical points tracking;flow visualization;importance measure;noise robustness;numerical schemes;spatial persistence;temporal evolution;time-aware feature hierarchy;tracking algorithms;Algorithm design and analysis;Feature extraction;Jacobian matrices;Joining processes;Manifolds;Noise;Noise measurement;Flow visualization;graph algorithms.\}, \
doi=\{10.1109/TVCG.2011.269\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6095545, \
author=\{Bramon, R. and Boada, I. and Bardera, A. and Rodriguez, J. and Feixas, M. and Puig, J. and Sbert, M.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Multimodal Data Fusion Based on Mutual Information\}, \
year=\{2012\}, \
month=\{Sept\}, \
volume=\{18\}, \
number=\{9\}, \
pages=\{1574-1587\}, \
abstract=\{Multimodal visualization aims at fusing different data sets so that the resulting combination provides more information and understanding to the user. To achieve this aim, we propose a new information-theoretic approach that automatically selects the most informative voxels from two volume data sets. Our fusion criteria are based on the information channel created between the two input data sets that permit us to quantify the information associated with each intensity value. This specific information is obtained from three different ways of decomposing the mutual information of the channel. In addition, an assessment criterion based on the information content of the fused data set can be used to analyze and modify the initial selection of the voxels by weighting the contribution of each data set to the final result. The proposed approach has been integrated in a general framework that allows for the exploration of volumetric data models and the interactive change of some parameters of the fused data set. The proposed approach has been evaluated on different medical data sets with very promising results.\}, \
keywords=\{content management;data visualisation;medical computing;sensor fusion;assessment criterion;information channel;information content;information-theoretic approach;informative voxels;intensity value;medical data sets;multimodal data visualization;mutual information decomposition;mutual information-based multimodal data fusion;volumetric data models exploration;Biomedical imaging;Data models;Data visualization;Image color analysis;Mutual information;Rendering (computer graphics);Transfer functions;Multimodal visualization;image fusion;information theory;mutual information.\}, \
doi=\{10.1109/TVCG.2011.280\}, \
ISSN=\{1077-2626\},\}}