@ARTICLE{6171181, 
author={Chentanez, N. and Mueller-Fischer, M.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={A Multigrid Fluid Pressure Solver Handling Separating Solid Boundary Conditions}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1191-1201}, 
abstract={We present a multigrid method for solving the linear complementarity problem (LCP) resulting from discretizing the Poisson equation subject to separating solid boundary conditions in an Eulerian liquid simulation's pressure projection step. The method requires only a few small changes to a multigrid solver for linear systems. Our generalized solver is fast enough to handle 3D liquid simulations with separating boundary conditions in practical domain sizes. Previous methods could only handle relatively small 2D domains in reasonable time, because they used expensive quadratic programming (QP) solvers. We demonstrate our technique in several practical scenarios, including nonaxis-aligned containers and moving solids in which the omission of separating boundary conditions results in disturbing artifacts of liquid sticking to solids. Our measurements show, that the convergence rate of our LCP solver is close to that of a standard multigrid solver.}, 
keywords={Poisson equation;computer graphics;differential equations;quadratic programming;3D liquid simulations;Eulerian liquid simulation;LCP;Poisson equation;QP solvers;linear complementarity problem;multigrid fluid pressure solver;pressure projection step;quadratic programming;solid boundary conditions;Boundary conditions;Equations;Linear systems;Mathematical model;Multigrid methods;Solid modeling;Solids;Multigrid;boundary condition;fluid simulation;linear complementarity;physics-based animation.}, 
doi={10.1109/TVCG.2012.86}, 
ISSN={1077-2626},}
@ARTICLE{6171182, 
author={Ando, R. and Thurey, Nils and Tsuruno, Reiji}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Preserving Fluid Sheets with Adaptively Sampled Anisotropic Particles}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1202-1214}, 
abstract={This paper presents a particle-based model for preserving fluid sheets of animated liquids with an adaptively sampled Fluid-Implicit-Particle (FLIP) method. In our method, we preserve fluid sheets by filling the breaking sheets with particle splitting in the thin regions, and by collapsing them in the deep water. To identify the critically thin parts, we compute the anisotropy of the particle neighborhoods, and use this information as a resampling criterion to reconstruct thin liquid surfaces. Unlike previous approaches, our method does not suffer from diffusive surfaces or complex remeshing operations, and robustly handles topology changes with the use of a meshless representation. We extend the underlying FLIP model with an anisotropic position correction to improve the particle spacing, and adaptive sampling to efficiently perform simulations of larger volumes. Due to the Lagrangian nature of our method, it can be easily implemented and efficiently parallelized. The results show that our method can produce visually complex liquid animations with thin structures and vivid motions.}, 
keywords={computational fluid dynamics;FLIP model;Lagrangian nature;adaptive sampling;animated liquids;anisotropic position correction;anisotropy;complex liquid animations;complex remeshing operation;deep water;fluid sheets;meshless representation;particle neighborhoods;particle spacing;particle splitting;particle-based model;resampling criterion;sampled anisotropic particles;sampled fluid implicit particle method;thin structures;topology change;vivid motions;Adaptation models;Boundary conditions;Computational modeling;Interpolation;Kernel;Mathematical model;Surface reconstruction;Physically based modeling;adaptive sampling.;fluid-implicit-particle method;liquid simulation;thin fluid sheets}, 
doi={10.1109/TVCG.2012.87}, 
ISSN={1077-2626},}
@ARTICLE{6171183, 
author={Haoda Huang and KangKang Yin and Ling Zhao and Yue Qi and Yizhou Yu and Xin Tong}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Detail-Preserving Controllable Deformation from Sparse Examples}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1215-1227}, 
abstract={Recent advances in laser scanning technology have made it possible to faithfully scan a real object with tiny geometric details, such as pores and wrinkles. However, a faithful digital model should not only capture static details of the real counterpart but also be able to reproduce the deformed versions of such details. In this paper, we develop a data-driven model that has two components; the first accommodates smooth large-scale deformations and the second captures high-resolution details. Large-scale deformations are based on a nonlinear mapping between sparse control points and bone transformations. A global mapping, however, would fail to synthesize realistic geometries from sparse examples, for highly deformable models with a large range of motion. The key is to train a collection of mappings defined over regions locally in both the geometry and the pose space. Deformable fine-scale details are generated from a second nonlinear mapping between the control points and per-vertex displacements. We apply our modeling scheme to scanned human hand models, scanned face models, face models reconstructed from multiview video sequences, and manually constructed dinosaur models. Experiments show that our deformation models, learned from extremely sparse training data, are effective and robust in synthesizing highly deformable models with rich fine features, for keyframe animation as well as performance-driven animation. We also compare our results with those obtained by alternative techniques.}, 
keywords={computational geometry;computer animation;feature extraction;image reconstruction;image sequences;solid modelling;video signal processing;bone transformation;data-driven model;detail-preserving controllable deformation sparse examples;face model reconstruction;faithful digital model;geometry;global mapping;high-resolution detail capture;keyframe animation;laser scanning technology;manually constructed dinosaur model;multiview video sequence;nonlinear mapping;object pores;object wrinkles;per-vertex displacement;performance-driven animation;pose space;scanned face model;scanned human hand model;smooth large-scale deformation;sparse control points;static detail capture;tiny geometric details;Animation;Bones;Data models;Deformable models;Face;Geometry;Training;CCA regression.;Detail-preserving deformation;controllable skinning;learning from sparse examples;Adult;Animals;Artificial Intelligence;Computer Graphics;Computer Simulation;Dinosaurs;Face;Hand;Humans;Image Processing, Computer-Assisted;Male;Models, Biological;Regression Analysis;Video Recording}, 
doi={10.1109/TVCG.2012.88}, 
ISSN={1077-2626},}
@ARTICLE{6165281, 
author={Kim, T. and James, D.L.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Physics-Based Character Skinning Using Multidomain Subspace Deformations}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1228-1240}, 
abstract={In this extended version of our Symposium on Computer Animation paper, we describe a domain-decomposition method to simulate articulated deformable characters entirely within a subspace framework. We have added a parallelization and eigendecomposition performance analysis, and several additional examples to the original symposium version. The method supports quasistatic and dynamic deformations, nonlinear kinematics and materials, and can achieve interactive time-stepping rates. To avoid artificial rigidity, or "locking,‚Äù associated with coupling low-rank domain models together with hard constraints, we employ penalty-based coupling forces. The multidomain subspace integrator can simulate deformations efficiently, and exploits efficient subspace-only evaluation of constraint forces between rotated domains using a novel Fast Sandwich Transform (FST). Examples are presented for articulated characters with quasistatic and dynamic deformations, and interactive performance with hundreds of fully coupled modes. Using our method, we have observed speedups of between 3 and 4 orders of magnitude over full-rank, unreduced simulations.}, 
keywords={computer animation;deformation;eigenvalues and eigenfunctions;interactive systems;transforms;FST;articulated deformable character simulation;artificial rigidity avoidance;computer animation;constraint forces;domain-decomposition method;dynamic deformation;eigendecomposition performance analysis;fast sandwich transform;full-rank unreduced simulations;hard constraints;interactive time-stepping rates;low-rank domain model coupling;multidomain subspace deformations;multidomain subspace integrator;nonlinear kinematics;parallelization performance analysis;penalty-based coupling forces;physics-based character skinning;quasistatic deformation;rotated domains;subspace-only evaluation;Animation;Computational modeling;Couplings;Deformable models;Force;Springs;Transforms;Domain decomposition;character animation;deformation;parallelization.;reduced-order modeling;subspace dynamics;Algorithms;Computer Graphics;Computer Simulation;Humans;Image Processing, Computer-Assisted}, 
doi={10.1109/TVCG.2012.78}, 
ISSN={1077-2626},}
@ARTICLE{6200365, 
author={Spillmann, J. and Harders, M.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Robust Interactive Collision Handling between Tools and Thin Volumetric Objects}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1241-1254}, 
abstract={Treating the interactions of soft tissue with rigid user-guided tools is a difficult problem. This is particularly true if the soft tissue has a slender shape, i.e., resembling a thin shell, and if the underlying numerical time-integration scheme employs large time steps. In this case, large mutual displacements of both the tool and the soft tissue occur frequently, resulting in deep interpenetrations or breakthroughs. As a consequence, the computation of spatially and temporally coherent contact spaces turns out to be very challenging. In this paper, an approach is proposed that is tailored to these kinds of interactions. To solve this problem, a novel spatially reduced representation of the soft tissue geometry is employed where the dominant dimensions of the object are approximated by a 2D triangle surface, while the third dimension is given in terms of nodal radii. To construct a feasible, nonpenetrating configuration, a novel manifold projection scheme is presented where the colliding triangles are rasterized into a distance field in order to robustly estimate the contact spaces, even for large intersections. The method produces physically plausible results, albeit it is purely geometric, and the material parameters are neglected at the collision response stage. Various examples, including an interactive prototype arthroscopy simulator, underline the wide applicability of the approach.}, 
keywords={biological tissues;computational geometry;interactive systems;medical computing;surgery;2D triangle surface;colliding triangles;collision response stage;interactive prototype arthroscopy simulator;manifold projection scheme;material parameters;mutual displacements;numerical time-integration scheme;rigid user guided tools;robust interactive collision handling;soft tissue geometry;spatially coherent contact spaces;spatially reduced representation;temporally coherent contact spaces;thin volumetric objects;Biological tissues;Computational modeling;Deformable models;Geometry;Manifolds;Robustness;Shape;Gauss-Seidel.;Physically based simulation;collision handling;distance fields;soft tissue;Algorithms;Arthroscopy;Computer Graphics;Computer Simulation;Humans;Image Processing, Computer-Assisted;Menisci, Tibial;Surgery, Computer-Assisted}, 
doi={10.1109/TVCG.2011.151}, 
ISSN={1077-2626},}
@ARTICLE{6035704, 
author={Biggers, K. and Keyser, J.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Inference-Based Surface Reconstruction of Cluttered Environments}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1255-1267}, 
abstract={We present an inference-based surface reconstruction algorithm that is capable of identifying objects of interest among a cluttered scene, and reconstructing solid model representations even in the presence of occluded surfaces. Our proposed approach incorporates a predictive modeling framework that uses a set of user-provided models for prior knowledge, and applies this knowledge to the iterative identification and construction process. Our approach uses a local to global construction process guided by rules for fitting high-quality surface patches obtained from these prior models. We demonstrate the application of this algorithm on several example data sets containing heavy clutter and occlusion.}, 
keywords={hidden feature removal;solid modelling;surface reconstruction;cluttered environments;construction process;inference based surface reconstruction;iterative identification;occluded surfaces;predictive modeling;solid model representations;surface reconstruction;user provided models;Computational modeling;Object recognition;Shape;Solid modeling;Solids;Surface reconstruction;Surface treatment;Three-dimensional/stereo scene analysis;object recognition;segmentation;surface fitting.}, 
doi={10.1109/TVCG.2011.263}, 
ISSN={1077-2626},}
@ARTICLE{6060815, 
author={Tingbo Hou and Hong Qin}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Robust Dense Registration of Partial Nonrigid Shapes}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1268-1280}, 
abstract={This paper presents a complete and robust solution for dense registration of partial nonrigid shapes. Its novel contributions are founded upon the newly proposed heat kernel coordinates (HKCs) that can accurately position points on the shape, and the priority-vicinity search that ensures geometric compatibility during the registration. HKCs index points by computing heat kernels from multiple sources, and their magnitudes serve as priorities of queuing points in registration. We start with shape features as the sources of heat kernels via feature detection and matching. Following the priority order of HKCs, the dense registration is progressively propagated from feature sources to all points. Our method has a superior indexing ability that can produce dense correspondences with fewer flips. The diffusion nature of HKCs, which can be interpreted as a random walk on a manifold, makes our method robust to noise and small holes avoiding surface surgery and repair. Our method searches correspondence only in a small vicinity of registered points, which significantly improves the time performance. Through comprehensive experiments, our new method has demonstrated its technical soundness and robustness by generating highly compatible dense correspondences.}, 
keywords={feature extraction;geometry;image matching;image registration;object detection;random processes;search problems;shape recognition;solid modelling;HKC index point;feature detection;feature matching;feature source propagation;geometric compatibility;heat kernel coordinates;magnitude;partial nonrigid shape;priority-vicinity search;queuing point;random walk;robust dense registration;shape feature;Eigenvalues and eigenfunctions;Feature extraction;Heating;Kernel;Manifolds;Robustness;Shape;Dense registration;heat kernel coordinates.;partial nonrigid shape}, 
doi={10.1109/TVCG.2011.267}, 
ISSN={1077-2626},}
@ARTICLE{5999663, 
author={Yizhong Zhang and Huamin Wang and Shuai Wang and Yiying Tong and Kun Zhou}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={A Deformable Surface Model for Real-Time Water Drop Animation}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1281-1289}, 
abstract={A water drop behaves differently from a large water body because of its strong viscosity and surface tension under the small scale. Surface tension causes the motion of a water drop to be largely determined by its boundary surface. Meanwhile, viscosity makes the interior of a water drop less relevant to its motion, as the smooth velocity field can be well approximated by an interpolation of the velocity on the boundary. Consequently, we propose a fast deformable surface model to realistically animate water drops and their flowing behaviors on solid surfaces. Our system efficiently simulates water drop motions in a Lagrangian fashion, by reducing 3D fluid dynamics over the whole liquid volume to a deformable surface model. In each time step, the model uses an implicit mean curvature flow operator to produce surface tension effects, a contact angle operator to change droplet shapes on solid surfaces, and a set of mesh connectivity updates to handle topological changes and improve mesh quality over time. Our numerical experiments demonstrate a variety of physically plausible water drop phenomena at a real-time rate, including capillary waves when water drops collide, pinch-off of water jets, and droplets flowing over solid materials. The whole system performs orders-of-magnitude faster than existing simulation approaches that generate comparable water drop effects.}, 
keywords={approximation theory;capillary waves;computational fluid dynamics;computer animation;contact angle;deformation;drops;flow simulation;interpolation;jets;mesh generation;surface tension;two-phase flow;viscosity;water;3D fluid dynamics;Lagrangian theory;approximation theory;boundary surface;capillary wave;contact angle;contact angle operator;deformable surface model;droplets;flow simulation;interpolation;mean curvature flow operator;mesh connectivity;mesh quality over time;pinch off;real-time water drop animation;solid material;solid surface;surface tension effect;viscosity;water drop motion;water drop phenomena;water jet;Deformable models;Force;Numerical models;Solids;Surface tension;Surface waves;Viscosity;Deformable surface model;mean curvature flow;surface tension;water drop simulation.}, 
doi={10.1109/TVCG.2011.141}, 
ISSN={1077-2626},}
@ARTICLE{6025349, 
author={Juan Cao and Xin Li and Chen, Zhonggui and Hong Qin}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Spherical DCB-Spline Surfaces with Hierarchical and Adaptive Knot Insertion}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1290-1303}, 
abstract={This paper develops a novel surface fitting scheme for automatically reconstructing a genus-0 object into a continuous parametric spline surface. A key contribution for making such a fitting method both practical and accurate is our spherical generalization of the Delaunay configuration B-spline (DCB-spline), a new non-tensor-product spline. In this framework, we efficiently compute Delaunay configurations on sphere by the union of two planar Delaunay configurations. Also, we develop a hierarchical and adaptive method that progressively improves the fitting quality by new knot-insertion strategies guided by surface geometry and fitting error. Within our framework, a genus-0 model can be converted to a single spherical spline representation whose root mean square error is tightly bounded within a user-specified tolerance. The reconstructed continuous representation has many attractive properties such as global smoothness and no auxiliary knots. We conduct several experiments to demonstrate the efficacy of our new approach for reverse engineering and shape modeling.}, 
keywords={computational geometry;least mean squares methods;mesh generation;splines (mathematics);surface fitting;tensors;Delaunay configuration B-spline;adaptive knot insertion;continuous parametric spline surface;genus-0 model;hierarchical knot insertion;nontensor-product spline;novel surface fitting scheme;reconstructed continuous representation;reverse engineering;root mean square error;shape modeling;spherical DCB-spline surfaces;spherical spline representation;surface geometry;Approximation methods;Electronic mail;Image reconstruction;Polynomials;Splines (mathematics);Surface reconstruction;Surface treatment;Delaunay configurations;knot insertion;knot placement;non-tensor-product B-splines.;spherical splines}, 
doi={10.1109/TVCG.2011.156}, 
ISSN={1077-2626},}
@ARTICLE{5989803, 
author={Youyi Zheng and Chiew-Lan Tai and Au, O.K.-C.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Dot Scissor: A Single-Click Interface for Mesh Segmentation}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1304-1312}, 
abstract={This paper presents a very easy-to-use interactive tool, which we call dot scissor, for mesh segmentation. The user's effort is reduced to placing only a single click where a cut is desired. Such a simple interface is made possible by a directional search strategy supported by a concavity-aware harmonic field and a robust voting scheme that selects the best isoline as the cut. With a concavity-aware weighting scheme, the harmonic fields gather dense isolines along concave regions which are natural boundaries of semantic components. The voting scheme relies on an isoline-face scoring mechanism that considers both shape geometry and user intent. We show by extensive experiments and quantitative analysis that our tool advances the state-of-the-art segmentation methods in both simplicity of use and segmentation quality.}, 
keywords={computer graphics;interactive systems;mesh generation;search problems;user interfaces;concavity-aware harmonic field;concavity-aware weighting scheme;directional search strategy;dot scissor;easy-to-use interactive tool;isoline-face scoring mechanism;mesh segmentation;natural boundaries;quantitative analysis;robust voting scheme;segmentation quality;semantic components;shape geometry;single-click interface;state-of-the-art segmentation methods;Brushes;Geometry;Gold;Harmonic analysis;Humans;Robustness;Shape;Interactive mesh segmentation;concavity aware;dot scissor;harmonic fields;voting.}, 
doi={10.1109/TVCG.2011.140}, 
ISSN={1077-2626},}
@ARTICLE{6007132, 
author={Shiravi, H. and Shiravi, A. and Ghorbani, A.A.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={A Survey of Visualization Systems for Network Security}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1313-1329}, 
abstract={Security Visualization is a very young term. It expresses the idea that common visualization techniques have been designed for use cases that are not supportive of security-related data, demanding novel techniques fine tuned for the purpose of thorough analysis. Significant amount of work has been published in this area, but little work has been done to study this emerging visualization discipline. We offer a comprehensive review of network security visualization and provide a taxonomy in the form of five use-case classes encompassing nearly all recent works in this area. We outline the incorporated visualization techniques and data sources and provide an informative table to display our findings. From the analysis of these systems, we examine issues and concerns regarding network security visualization and provide guidelines and directions for future researchers and visual system developers.}, 
keywords={computer network security;data visualisation;data sources;information visualization;informative table;network security visualization system;security-related data;taxonomy;use-case classes;Data visualization;Feature extraction;IP networks;Monitoring;Security;Servers;Visualization;Information visualization;network security visualization;visualization techniques.}, 
doi={10.1109/TVCG.2011.144}, 
ISSN={1077-2626},}
@ARTICLE{5963661, 
author={Kun-Chuan Feng and Chaoli Wang and Han-Wei Shen and Tong-Yee Lee}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Coherent Time-Varying Graph Drawing with Multifocus+Context Interaction}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1330-1342}, 
abstract={We present a new approach for time-varying graph drawing that achieves both spatiotemporal coherence and multifocus+context visualization in a single framework. Our approach utilizes existing graph layout algorithms to produce the initial graph layout, and formulates the problem of generating coherent time-varying graph visualization with the focus+context capability as a specially tailored deformation optimization problem. We adopt the concept of the super graph to maintain spatiotemporal coherence and further balance the needs for aesthetic quality and dynamic stability when interacting with time-varying graphs through focus+context visualization. Our method is particularly useful for multifocus+context visualization of time-varying graphs where we can preserve the mental map by preventing nodes in the focus from undergoing abrupt changes in size and location in the time sequence. Experiments demonstrate that our method strikes a good balance between maintaining spatiotemporal coherence and accentuating visual foci, thus providing a more engaging viewing experience for the users.}, 
keywords={graph theory;optimisation;aesthetic quality;coherent time-varying graph drawing;coherent time-varying graph visualization;deformation optimization problem;dynamic stability;focus+context capability;focus+context visualization;graph layout algorithms;multifocus+context interaction;multifocus+context visualization;spatiotemporal coherence;visual foci;Coherence;Context;Data visualization;Heuristic algorithms;Layout;Spatiotemporal phenomena;Visualization;Graph drawing;focus+context visualization.;spatiotemporal coherence;time-varying graphs}, 
doi={10.1109/TVCG.2011.128}, 
ISSN={1077-2626},}
@ARTICLE{5999664, 
author={Gorochowski, T.E. and di Bernardo, M. and Grierson, C.S.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Using Aging to Visually Uncover Evolutionary Processes on Networks}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1343-1352}, 
abstract={Networks are widely used to describe many natural and technological systems. Understanding how these evolve over time poses a challenge for existing visualization techniques originally developed for fixed network structures. We describe a method of incorporating the concept of aging into evolving networks, where nodes and edges store information related to the amount of local evolutionary change they have experienced. This property is used to generate visualizations that ensure stable substructures maintain relatively fixed spatial positions, allowing them to act as visual markers and providing context for evolutionary change elsewhere. By further supplementing these visualizations with color cues, the resultant animations enable a clearer portrayal of the underlying evolutionary process.}, 
keywords={computer animation;data visualisation;evolutionary computation;network theory (graphs);animation;color cues;evolutionary process;network aging;network structures;visual marker;visualization techniques;Aging;Animation;Color;Data visualization;Layout;Stability analysis;Visualization;Network evolution;graph layout.;information visualization;Algorithms;Computer Communication Networks;Computer Simulation;Humans;Models, Genetic;Social Support;Time Factors}, 
doi={10.1109/TVCG.2011.142}, 
ISSN={1077-2626},}
@ARTICLE{6025348, 
author={Hongfeng Yu and Chaoli Wang and Ching-Kuang Shene and Chen, J.H.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Hierarchical Streamline Bundles}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1353-1367}, 
abstract={Effective 3D streamline placement and visualization play an essential role in many science and engineering disciplines. The main challenge for effective streamline visualization lies in seed placement, i.e., where to drop seeds and how many seeds should be placed. Seeding too many or too few streamlines may not reveal flow features and patterns either because it easily leads to visual clutter in rendering or it conveys little information about the flow field. Not only does the number of streamlines placed matter, their spatial relationships also play a key role in understanding the flow field. Therefore, effective flow visualization requires the streamlines to be placed in the right place and in the right amount. This paper introduces hierarchical streamline bundles, a novel approach to simplifying and visualizing 3D flow fields defined on regular grids. By placing seeds and generating streamlines according to flow saliency, we produce a set of streamlines that captures important flow features near critical points without enforcing the dense seeding condition. We group spatially neighboring and geometrically similar streamlines to construct a hierarchy from which we extract streamline bundles at different levels of detail. Streamline bundles highlight multiscale flow features and patterns through clustered yet not cluttered display. This selective visualization strategy effectively reduces visual clutter while accentuating visual foci, and therefore is able to convey the desired insight into the flow data.}, 
keywords={critical points;flow visualisation;pattern clustering;pattern formation;rendering (computer graphics);3D flow field visualization;3D streamline placement;3D streamline visualization;critical points;flow data;flow saliency;geometrically similar streamlines;hierarchical streamline bundles;multiscale flow features;multiscale flow patterns;rendering;seed placement;spatial relationships;spatially neighboring streamlines;streamline bundle extraction;streamline seeding;visual clutter reduction;visual foci accentuation;Clustering algorithms;Data visualization;Diffusion tensor imaging;Feature extraction;Streaming media;Three dimensional displays;Visualization;Streamline bundles;flow saliency;flow visualization.;hierarchical clustering;level-of-detail;seed placement}, 
doi={10.1109/TVCG.2011.155}, 
ISSN={1077-2626},}
@ARTICLE{6143942, 
author={Barakat, S. and Garth, C. and Tricoche, X.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Interactive Computation and Rendering of Finite-Time Lyapunov Exponent Fields}, 
year={2012}, 
month={Aug}, 
volume={18}, 
number={8}, 
pages={1368-1380}, 
abstract={In this paper, we present a novel technique that allows for the coupled computation and visualization of salient flow structures at interactive frame rates. Our approach is built upon a hierarchical representation of the Finite-time Lyapunov Exponent (FTLE) field, which is adaptively sampled and rendered to meet the need of the current visual setting. The performance of our method allows the user to explore large and complex data sets across scales and to inspect their features at arbitrary resolution. The paper discusses an efficient implementation of this strategy on graphics hardware and provides results for an analytical flow and several CFD simulation data sets.}, 
keywords={Lyapunov methods;computational fluid dynamics;flow visualisation;coupled computation;finite time Lyapunov exponent fields;graphics hardware;hierarchical representation;interactive computation;salient flow structures visualization;simulation data sets;Graphics processing unit;Octrees;Rendering (computer graphics);Three dimensional displays;Transient analysis;Visualization;FTLE;Flow visualization;GPU and multicore architectures;interactive;streaming data.;vector field data}, 
doi={10.1109/TVCG.2012.33}, 
ISSN={1077-2626},}