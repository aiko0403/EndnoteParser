@ARTICLE{5728799, 
author={Guntury, S. and Narayanan, P. J.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Raytracing Dynamic Scenes on the GPU Using Grids}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={5-16}, 
abstract={Raytracing dynamic scenes at interactive rates have received a lot of attention recently. We present a few strategies for high performance raytracing on a commodity GPU. The construction of grids needs sorting, which is fast on today's GPUs. The grid is thus the acceleration structure of choice for dynamic scenes as per-frame rebuilding is required. We advocate the use of appropriate data structures for each stage of raytracing, resulting in multiple structure building per frame. A perspective grid built for the camera achieves perfect coherence for primary rays. A perspective grid built with respect to each light source provides the best performance for shadow rays. Spherical grids handle lights positioned inside the model space and handle spotlights. Uniform grids are best for reflection and refraction rays with little coherence. We propose an Enforced Coherence method to bring coherence to them by rearranging the ray to voxel mapping using sorting. This gives the best performance on GPUs with only user-managed caches. We also propose a simple, Independent Voxel Walk method, which performs best by taking advantage of the L1 and L2 caches on recent GPUs. We achieve over 10 fps of total rendering on the Conference model with one light source and one reflection bounce, while rebuilding the data structure for each stage. Ideas presented here are likely to give high performance on the future GPUs as well as other manycore architectures.}, 
keywords={cache storage;computer graphic equipment;coprocessors;data structures;grid computing;multiprocessing systems;ray tracing;rendering (computer graphics);sorting;GPU;L1 caches;L2 caches;camera;data structures;enforced coherence method;grids;high performance raytracing;independent voxel walk method;light source;manycore architectures;raytracing dynamic scenes;reflection rays;refraction rays;voxel mapping;Coherence;Data structures;Graphics processing unit;Instruction sets;Light sources;Tiles;GPU.;Raytracing;grids;load balancing;ray coherence}, 
doi={10.1109/TVCG.2011.46}, 
ISSN={1077-2626},}
@ARTICLE{5708139, 
author={Howison, M. and Bethel, E.W. and Childs, H.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Hybrid Parallelism for Volume Rendering on Large-, Multi-, and Many-Core Systems}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={17-29}, 
abstract={With the computing industry trending toward multi- and many-core processors, we study how a standard visualization algorithm, raycasting volume rendering, can benefit from a hybrid parallelism approach. Hybrid parallelism provides the best of both worlds: using distributed-memory parallelism across a large numbers of nodes increases available FLOPs and memory, while exploiting shared-memory parallelism among the cores within each node ensures that each node performs its portion of the larger calculation as efficiently as possible. We demonstrate results from weak and strong scaling studies, at levels of concurrency ranging up to 216,000, and with data sets as large as 12.2 trillion cells. The greatest benefit from hybrid parallelism lies in the communication portion of the algorithm, the dominant cost at higher levels of concurrency. We show that reducing the number of participants with a hybrid approach significantly improves performance.}, 
keywords={data visualisation;distributed shared memory systems;multiprocessing systems;parallel processing;rendering (computer graphics);FLOPs;communication portion;distributed-memory parallelism;hybrid parallelism approach;many-core processors;multicore processors;raycasting volume rendering;shared-memory parallelism;standard visualization algorithm;Concurrent computing;Graphics processing unit;Instruction sets;Parallel processing;Rendering (computer graphics);Tiles;Volume visualization;parallel processing.}, 
doi={10.1109/TVCG.2011.24}, 
ISSN={1077-2626},}
@ARTICLE{5708137, 
author={Fei Hou and Yue Qi and Hong Qin}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Drawing-Based Procedural Modeling of Chinese Architectures}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={30-42}, 
abstract={This paper presents a novel modeling framework to build 3D models of Chinese architectures from elevation drawing. Our algorithm integrates the capability of automatic drawing recognition with powerful procedural modeling to extract production rules from elevation drawing. First, different from the previous symbol-based floor plan recognition, based on the novel concept of repetitive pattern trees, small horizontal repetitive regions of the elevation drawing are clustered in a bottom-up manner to form architectural components with maximum repetition, which collectively serve as building blocks for 3D model generation. Second, to discover the global architectural structure and its components' interdependencies, the components are structured into a shape tree in a top-down subdivision manner and recognized hierarchically at each level of the shape tree based on Markov Random Fields (MRFs). Third, shape grammar rules can be derived to construct 3D semantic model and its possible variations with the help of a 3D component repository. The salient contribution lies in the novel integration of procedural modeling with elevation drawing, with a unique application to Chinese architectures.}, 
keywords={Markov processes;architectural CAD;solid modelling;technical drawing;trees (mathematics);3D component repository;3D model generation;Chinese architectures;Markov random fields;automatic drawing recognition;drawing based procedural modeling;elevation drawing;global architectural structure;production rules;repetitive pattern trees;shape grammar rules;shape tree;subdivision manner;symbol based floor plan recognition;Computational modeling;Computer architecture;Grammar;Pixel;Shape;Solid modeling;Three dimensional displays;Chinese architecture.;Procedural modeling;elevation drawing recognition;elevation drawing segmentation}, 
doi={10.1109/TVCG.2011.22}, 
ISSN={1077-2626},}
@ARTICLE{5669301, 
author={Farin, G.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Shape Measures for Triangles}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={43-46}, 
abstract={We compare a variety of triangle shape measures using concepts such as smoothness and convexity. We show that one of these measures, the elongation measure, lends itself to an intuitive geometric interpretation.}, 
keywords={computational geometry;elongation measurement;geometric interpretation;triangle shape measurement;Eigenvalues and eigenfunctions;Interpolation;Joining processes;Lead;Loss measurement;Shape;Shape measurement;Shape;circumellipse.;condition number;triangle}, 
doi={10.1109/TVCG.2010.256}, 
ISSN={1077-2626},}
@ARTICLE{5669303, 
author={Wald, I.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Fast Construction of SAH BVHs on the Intel Many Integrated Core (MIC) Architecture}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={47-57}, 
abstract={We investigate how to efficiently build bounding volume hierarchies (BVHs) with surface area heuristic (SAH) on the Intel Many Integrated Core (MIC) Architecture. To achieve maximum performance, we use four key concepts: progressive 10-bit quantization to reduce cache footprint with negligible loss in BVH quality; an AoSoA data layout that allows efficient streaming and SIMD processing; high-performance SIMD kernels for binning and partitioning; and a parallelization framework with several build-specific optimizations. The resulting system is more than an order of magnitude faster than today's high-end GPU builders for comparable BVHs; it is usually faster even than spatial median builders; it can build SAH BVHs almost as fast as existing GPUs and CPUs- and CPU-based approaches can build regular grids; and in aggregate "build+render” performance is significantly faster than the best published numbers for either of these systems, be it CPU or GPU, BVH, kd-tree, or grid.}, 
keywords={computer architecture;computer graphic equipment;coprocessors;multiprocessing systems;parallel processing;AoSoA data layout;BVH;GPU;Intel many integrated core architecture;MIC;SAH;SIMD kernels;SIMD processing;bounding volume hierarchies;parallelization framework;surface area heuristic;Arrays;Instruction sets;Kernel;Layout;Merging;Registers;Bounding volume hierarchies (BVHs);Intel MIC architecture.;parallel BVH construction;surface area heuristic (SAH)}, 
doi={10.1109/TVCG.2010.251}, 
ISSN={1077-2626},}
@ARTICLE{5728800, 
author={Jong-Chul Yoon and In-Kwon Lee and Kang, Henry}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Video Painting Based on a Stabilized Time-Varying Flow Field}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={58-67}, 
abstract={We present a method for constructing 3D feature flow from video and its application to video stylization. Our method extracts smoothly aligned 3D vectors that describe the smallest variation of colors within a spatiotemporal video cube, and thus effectively preserves both spatial and temporal coherence in a relatively inexpensive manner. As an application of this flow field we present a particle-based video stylization technique to rerender the video in a feature enhancing, painterly style. Our method consists of per-pixel operations and is suitable for GPU implementation, which enables real-time video stylization.}, 
keywords={computer graphic equipment;coprocessors;image colour analysis;rendering (computer graphics);video signal processing;3D feature flow construction;3D vectors;GPU implementation;color variation;nonphotorealistic rendering;particle based video stylization technique;spatiotemporal video cube;stabilized time varying flow field;video painting;video stylization;Coherence;Color;Image color analysis;Painting;Pixel;Rendering (computer graphics);Three dimensional displays;Nonphotorealistic rendering;flow-based filtering;painterly rendering.;video abstraction}, 
doi={10.1109/TVCG.2011.47}, 
ISSN={1077-2626},}
@ARTICLE{5710904, 
author={Brown, J.A. and Capson, D.W.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={A Framework for 3D Model-Based Visual Tracking Using a GPU-Accelerated Particle Filter}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={68-80}, 
abstract={A novel framework for acceleration of particle filtering approaches to 3D model-based, markerless visual tracking in monocular video is described. Specifically, we present a methodology for partitioning and mapping the computationally expensive weight-update stage of a particle filter to a graphics processing unit (GPU) to achieve particle- and pixel-level parallelism. Nvidia CUDA and Direct3D are employed to harness the massively parallel computational power of modern GPUs for simulation (3D model rendering) and evaluation (segmentation, feature extraction, and weight calculation) of hundreds of particles at high speeds. The proposed framework addresses the computational intensity that is intrinsic to all particle filter approaches, including those that have been modified to minimize the number of particles required for a particular task. Performance and tracking quality results for rigid object and articulated hand tracking experiments demonstrate markerless, model-based visual tracking on consumer-grade graphics hardware with pixel-level accuracy up to 95 percent at 60+ frames per second. The framework accelerates particle evaluation up to 49 times over a comparable CPU-only implementation, providing an increased particle count while maintaining real-time frame rates.}, 
keywords={computer graphics;coprocessors;object tracking;particle filtering (numerical methods);3D model based visual tracking framework;3D model rendering;Direct3D;GPU accelerated particle filter;Nvidia CUDA;computational intensity;consumer grade graphics;graphics processing unit;markerless visual tracking;monocular video;parallel computational power;particle and pixel level parallelism;Computational modeling;Feature extraction;Graphics processing unit;Solid modeling;Target tracking;Three dimensional displays;Visualization;Edge and feature detection;Monte Carlo simulation;graphics processors;tracking;vision I/O.}, 
doi={10.1109/TVCG.2011.34}, 
ISSN={1077-2626},}
@ARTICLE{5674033, 
author={Purchase, H.C. and Pilcher, C. and Plimmer, B.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Graph Drawing Aesthetics_Created by Users, Not Algorithms}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={81-92}, 
abstract={Prior empirical work on layout aesthetics for graph drawing algorithms has concentrated on the interpretation of existing graph drawings. We report on experiments which focus on the creation and layout of graph drawings: participants were asked to draw graphs based on adjacency lists, and to lay them out "nicely.” Two interaction methods were used for creating the drawings: a sketch interface which allows for easy, natural hand movements, and a formal point-and-click interface similar to a typical graph editing system. We find, in common with many other studies, that removing edge crossings is the most significant aesthetic, but also discover that aligning nodes and edges to an underlying grid is important. We observe that the aesthetics favored by participants during creation of a graph drawing are often not evident in the final product and that the participants did not make a clear distinction between the processes of creation and layout. Our results suggest that graph drawing systems should integrate automatic layout with the user's manual editing process, and provide facilities to support grid-based graph creation.}, 
keywords={computational geometry;graph theory;adjacency lists;edge crossings;formal point-and-click interface;graph drawing aesthetics;graph editing system;interaction methods;sketch interface;Algorithm design and analysis;Computer science;Education;Electronic mail;Humans;Interviews;Layout;Evaluation/methodology;graphs and networks;user interfaces.}, 
doi={10.1109/TVCG.2010.269}, 
ISSN={1077-2626},}
@ARTICLE{5611507, 
author={Dongning Luo and Jing Yang and Krstajic, M. and Ribarsky, W. and Keim, D.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={EventRiver: Visually Exploring Text Collections with Temporal References}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={93-105}, 
abstract={Many text collections with temporal references, such as news corpora and weblogs, are generated to report and discuss real life events. Thus, event-related tasks, such as detecting real life events that drive the generation of the text documents, tracking event evolutions, and investigating reports and commentaries about events of interest, are important when exploring such text collections. To incorporate and leverage human efforts in conducting such tasks, we propose a novel visual analytics approach named EventRiver. EventRiver integrates event-based automated text analysis and visualization to reveal the events motivating the text generation and the long term stories they construct. On the visualization, users can interactively conduct tasks such as event browsing, tracking, association, and investigation. A working prototype of EventRiver has been implemented for exploring news corpora. A set of case studies, experiments, and a preliminary user test have been conducted to evaluate its effectiveness and efficiency.}, 
keywords={data visualisation;text analysis;EventRiver;Weblogs;event browsing;event-based automated text analysis;event-related tasks;news corpora;temporal references;text generation;text visualization;visual analytics approach;visually exploring text collections;Bismuth;Clustering algorithms;Context;Humans;Semantics;Text analysis;Visualization;Visual analytics;clustering.;event;information visualization;text;topic;Cluster Analysis;Computer Graphics;Database Management Systems;Databases, Factual;Humans;Mass Media;Models, Theoretical;Semantics;Time Factors;User-Computer Interface}, 
doi={10.1109/TVCG.2010.225}, 
ISSN={1077-2626},}
@ARTICLE{5669304, 
author={Correa, C. and Crnovrsanin, T. and Kwan-Liu Ma}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Visual Reasoning about Social Networks Using Centrality Sensitivity}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={106-120}, 
abstract={In this paper, we study the sensitivity of centrality metrics as a key metric of social networks to support visual reasoning. As centrality represents the prestige or importance of a node in a network, its sensitivity represents the importance of the relationship between this and all other nodes in the network. We have derived an analytical solution that extracts the sensitivity as the derivative of centrality with respect to degree for two centrality metrics based on feedback and random walks. We show that these sensitivities are good indicators of the distribution of centrality in the network, and how changes are expected to be propagated if we introduce changes to the network. These metrics also help us simplify a complex network in a way that retains the main structural properties and that results in trustworthy, readable diagrams. Sensitivity is also a key concept for uncertainty analysis of social networks, and we show how our approach may help analysts gain insight on the robustness of key network metrics. Through a number of examples, we illustrate the need for measuring sensitivity, and the impact it has on the visualization of and interaction with social and other scale-free networks.}, 
keywords={complex networks;data visualisation;inference mechanisms;social networking (online);centrality metrics sensitivity;complex network;feedback;random walks;scale free networks;social networks;uncertainty analysis;visual reasoning;Cognition;Layout;Markov processes;Sensitivity;Social network services;Visualization;Social network visualization;centrality;eigenvector and Markov importance.;sensitivity analysis;Algorithms;Cluster Analysis;Computer Simulation;Databases, Factual;Markov Chains;Models, Theoretical;Reproducibility of Results;Sensitivity and Specificity;Social Support}, 
doi={10.1109/TVCG.2010.260}, 
ISSN={1077-2626},}
@ARTICLE{5708138, 
author={Lei Wang and Xin Zhao and Kaufman, A.E.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Modified Dendrogram of Attribute Space for Multidimensional Transfer Function Design}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={121-131}, 
abstract={We introduce a modified dendrogram (MD) (with subtrees to represent clusters) and display it in 2D for multidimensional transfer function design. Such a transfer function for direct volume rendering employs a multidimensional space, termed attribute space. The MD reveals the hierarchical structure information of the attribute space. The user can design a transfer function in an intuitive and informative manner using the MD user interface in 2D instead of multidimensional space, where it is hard to ascertain the relationship of the space. In addition, we provide the capability to interactively modify the granularity of the MD. The coarse-grained MD primarily shows the global information of the attribute space while the fine-grained MD reveals the finer details, and the separation ability of the attribute space is completely preserved in the finest granularity. With this so called multigrained method, the user can efficiently create a transfer function using the coarse-grained MD, and then fine tune it with the fine-grained MDs. Our method is independent on the type of the attributes and supports arbitrary-dimension attribute space.}, 
keywords={rendering (computer graphics);user interfaces;MD user interface;direct volume rendering;modified attribute space dendrogram;multidimensional transfer function design;multigrained method;termed attribute space;Aerospace electronics;Clustering algorithms;Complexity theory;Rendering (computer graphics);Transfer functions;User interfaces;Visualization;Volume visualization;hierarchical;multidimensional;multivariate visualization.}, 
doi={10.1109/TVCG.2011.23}, 
ISSN={1077-2626},}
@ARTICLE{5669302, 
author={Bryden, A. and Phillips, G.N. and Gleicher, M.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Automated Illustration of Molecular Flexibility}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={132-145}, 
abstract={In this paper, we present an approach to creating illustrations of molecular flexibility using normal mode analysis (NMA). The output of NMA is a collection of points corresponding to the locations of atoms and associated motion vectors, where a vector for each point is known. Our approach abstracts the complex object and its motion by grouping the points, models the motion of each group as an affine velocity, and depicts the motion of each group by automatically choosing glyphs such as arrows. Affine exponentials allow the extrapolation of nonlinear effects such as near rotations and spirals from the linear velocities. Our approach automatically groups points by finding sets of neighboring points whose motions fit the motion model. The geometry and motion models for each group are used to determine glyphs that depict the motion, with various aspects of the motion mapped to each glyph. We evaluated the utility of our system in real work done by structural biologists both by utilizing it in our own structural biology work and quantitatively measuring its usefulness on a set of known protein conformation changes. Additionally, in order to allow ourselves and our collaborators to effectively use our techniques we integrated our system with commonly used tools for molecular visualization.}, 
keywords={affine transforms;biology computing;computational geometry;data visualisation;extrapolation;molecular biophysics;physics computing;proteins;affine exponentials;arrows;automated molecular flexibility illustration;geometry;glyphs;linear velocities;molecular visualization;motion models;near rotations;nonlinear effects extrapolation;normal mode analysis;protein conformation changes;spirals;structural biology work;Amino acids;Animation;Computational modeling;Data visualization;Mathematical model;Proteins;Visualization;Illustration;molecular visualization.;motion}, 
doi={10.1109/TVCG.2010.250}, 
ISSN={1077-2626},}
@ARTICLE{5710907, 
author={Doraiswamy, H. and Natarajan, V.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={Output-Sensitive Construction of Reeb Graphs}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={146-159}, 
abstract={The Reeb graph of a scalar function represents the evolution of the topology of its level sets. This paper describes a near-optimal output-sensitive algorithm for computing the Reeb graph of scalar functions defined over manifolds or non-manifolds in any dimension. Key to the simplicity and efficiency of the algorithm is an alternate definition of the Reeb graph that considers equivalence classes of level sets instead of individual level sets. The algorithm works in two steps. The first step locates all critical points of the function in the domain. Critical points correspond to nodes in the Reeb graph. Arcs connecting the nodes are computed in the second step by a simple search procedure that works on a small subset of the domain that corresponds to a pair of critical points. The paper also describes a scheme for controlled simplification of the Reeb graph and two different graph layout schemes that help in the effective presentation of Reeb graphs for visual analysis of scalar fields. Finally, the Reeb graph is employed in four different applications-surface segmentation, spatially-aware transfer function design, visualization of interval volumes, and interactive exploration of time-varying data.}, 
keywords={computational geometry;graph theory;search problems;set theory;interactive time varying data exploration;interval volume visualization;level sets;near optimal output sensitive algorithm;output sensitive Reeb graphs construction;scalar function;search procedure;spatially aware transfer function design;surface segmentation;topology evolution;visual scalar field analysis;Algorithm design and analysis;Heuristic algorithms;Isosurfaces;Layout;Level set;Manifolds;Topology;Computational topology;Reeb graphs;graph layout.;level set topology;scalar functions;simplification}, 
doi={10.1109/TVCG.2011.37}, 
ISSN={1077-2626},}
@ARTICLE{5753890, 
author={Shafii, S. and Dillard, S.E. and Hlawitschka, M. and Hamann, B.}, 
journal={Visualization and Computer Graphics, IEEE Transactions on}, 
title={The Topological Effects of Smoothing}, 
year={2012}, 
month={Jan}, 
volume={18}, 
number={1}, 
pages={160-172}, 
abstract={Scientific data sets generated by numerical simulations or experimental measurements often contain a substantial amount of noise. Smoothing the data removes noise but can have potentially drastic effects on the qualitative nature of the data, thereby influencing its characterization and visualization via topological analysis, for example. We propose a method to track topological changes throughout the smoothing process. As a preprocessing step, we oversmooth the data and collect a list of topological events, specifically the creation and destruction of extremal points. During rendering, it is possible to select the number of topological events by interactively manipulating a merging parameter. The result that a specific amount of smoothing has on the topology of the data is illustrated using a topology-derived transfer function that relates region connectivity of the smoothed data to the original regions of the unsmoothed data. This approach enables visual as well as quantitative analysis of the topological effects of smoothing.}, 
keywords={computational geometry;data handling;data visualisation;rendering (computer graphics);scientific information systems;topology;data smoothing;numerical simulations;rendering;scientific data sets;topological smoothing effects;topology derived transfer function;visualization;Data visualization;Level set;Rendering (computer graphics);Smoothing methods;Topology;Tracking;Vegetation;Volume visualization;smoothing.;visualization techniques and methodologies}, 
doi={10.1109/TVCG.2011.74}, 
ISSN={1077-2626},}