{\rtf1\ansi\ansicpg1252\cocoartf1265\cocoasubrtf190
{\fonttbl\f0\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;}
\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\deftab720
\pard\pardeftab720

\f0\fs24 \cf0 @ARTICLE\{6143941, \
author=\{Lei Liu and Van Liere, R.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Modeling Object Pursuit for Desktop Virtual Reality\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1017-1026\}, \
abstract=\{Models of interaction tasks are quantitative descriptions of relationships between human temporal performance and the spatial characteristics of the interactive tasks. Examples include Fitts' law for modeling the pointing task and Accot and Zhai's steering law for the path steering task. Interaction models can be used as guidelines to design efficient user interfaces and quantitatively evaluate interaction techniques and input devices. In this paper, we introduce and experimentally verify an interaction model for a 3D object-pursuit interaction task. Object pursuit requires that a user continuously tracks an object that moves with constant velocities in a desktop virtual environment. For modeling purposes, we divide the total object-pursuit movement into a tracking phase and a correction phase. Following a two-step modeling methodology that is originally proposed in this paper, the time for the correction phase is modeled as a function of path length, path curvature, target width, and target velocity. The object-pursuit model can be used to quantitatively evaluate the efficiency of user interfaces that involve 3D interaction with moving objects.\}, \
keywords=\{user interfaces;virtual reality;3D object-pursuit interaction task;Accot;Fitts law;Zhai steering law;correction phase;desktop virtual reality;human temporal performance;input devices;moving objects;path curvature;path length;path steering task;pointing task;quantitatively evaluate interaction techniques;spatial characteristics;target velocity;target width;tracking phase;two-step modeling methodology;user interfaces;Computational modeling;Equations;Mathematical model;Solid modeling;Target tracking;Virtual environments;3D interaction;interaction modeling;object pursuit.;Adult;Analysis of Variance;Computer Graphics;Computers;Feedback, Sensory;Female;Humans;Male;Models, Theoretical;Psychomotor Performance;Regression Analysis;Statistics, Nonparametric;User-Computer Interface;Video Games\}, \
doi=\{10.1109/TVCG.2012.31\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6086538, \
author=\{Petkov, K. and Papadopoulos, C. and Min Zhang and Kaufman, A.E. and Xianfeng Gu\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Interactive Visibility Retargeting in VR Using Conformal Visualization\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1027-1040\}, \
abstract=\{In Virtual Reality, immersive systems such as the CAVE provide an important tool for the collaborative exploration of large 3D data. Unlike head-mounted displays, these systems are often only partially immersive due to space, access, or cost constraints. The resulting loss of visual information becomes a major obstacle for critical tasks that need to utilize the users' entire field of vision. We have developed a conformal visualization technique that establishes a conformal mapping between the full 360^circ field of view and the display geometry of a given visualization system. The mapping is provably angle-preserving and has the desirable property of preserving shapes locally, which is important for identifying shape-based features in the visual data. We apply the conformal visualization to both forward and backward rendering pipelines in a variety of retargeting scenarios, including CAVEs and angled arrangements of flat panel displays. In contrast to image-based retargeting approaches, our technique constructs accurate stereoscopic images that are free of resampling artifacts. Our user study shows that on the visual polyp detection task in Immersive Virtual Colonoscopy, conformal visualization leads to imprrenderingoved sensitivity at comparable examination times against the traditional rendering approach. We also develop a novel user interface based on the interactive recreation of the conformal mapping and the real-time regeneration of the view direction correspondence.\}, \
keywords=\{conformal mapping;data visualisation;user interfaces;virtual reality;backward rendering pipelines;conformal mapping;conformal visualization technique;forward rendering pipelines;immersive virtual colonoscopy;interactive visibility;real-time regeneration;shape-based features;stereoscopic images;user interface;virtual reality;visual information;visual polyp detection task;Conformal mapping;Data visualization;Geometry;Measurement;Rendering (computer graphics);Shape;Visualization;CAVE;GPU;Ricci flow;Virtual reality;conformal visualization;immersive cabin;partially immersive.;Algorithms;Colonic Polyps;Colonoscopy;Computer Graphics;Depth Perception;Humans;Models, Theoretical;Sensitivity and Specificity;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2011.278\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6200791, \
author=\{Neth, C.T. and Souman, J.L. and Engel, D. and Kloos, U. and Bulthoff, H.H. and Mohler, B.J.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Velocity-Dependent Dynamic Curvature Gain for Redirected Walking\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1041-1052\}, \
abstract=\{Redirected walking techniques allow people to walk in a larger virtual space than the physical extents of the laboratory. We describe two experiments conducted to investigate human sensitivity to walking on a curved path and to validate a new redirected walking technique. In a psychophysical experiment, we found that sensitivity to walking on a curved path was significantly lower for slower walking speeds (radius of 10 m versus 22 m). In an applied study, we investigated the influence of a velocity-dependent dynamic gain controller and an avatar controller on the average distance that participants were able to freely walk before needing to be reoriented. The mean walked distance was significantly greater in the dynamic gain controller condition, as compared to the static controller (22 m versus 15 m). Our results demonstrate that perceptually motivated dynamic redirected walking techniques, in combination with reorientation techniques, allow for unaided exploration of a large virtual city model.\}, \
keywords=\{avatars;gain control;gait analysis;psychology;avatar controller;curved path;dynamic gain controller condition;human walking sensitivity;psychophysical experiment;redirected walking techniques;reorientation techniques;static controller;velocity-dependent dynamic curvature gain;velocity-dependent dynamic gain controller;virtual city model;virtual space;Atmospheric measurements;Games;Legged locomotion;Particle measurements;Sensitivity;Trajectory;Virtual environments;Virtual reality;avatars.;curvature sensitivity;redirected walking;virtual locomotion;Adult;Algorithms;Analysis of Variance;Computer Graphics;Female;Humans;Male;Middle Aged;Orientation;User-Computer Interface;Walking\}, \
doi=\{10.1109/TVCG.2011.275\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6109251, \
author=\{Peck, T.C. and Fuchs, H. and Whitton, M.C.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{The Design and Evaluation of a Large-Scale Real-Walking Locomotion Interface\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1053-1067\}, \
abstract=\{Redirected Free Exploration with Distractors (RFEDs) is a large-scale real-walking locomotion interface developed to enable people to walk freely in Virtual Environments (VEs) that are larger than the tracked space in their facility. This paper describes the RFED system in detail and reports on a user study that evaluated RFED by comparing it to Walking-in-Place (WIP) and Joystick (JS) interfaces. The RFED system is composed of two major components, redirection and distractors. This paper discusses design challenges, implementation details, and lessons learned during the development of two working RFED systems. The evaluation study examined the effect of the locomotion interface on users' cognitive performance on navigation and wayfinding measures. The results suggest that participants using RFED were significantly better at navigating and wayfinding through virtual mazes than participants using walking-in-place and joystick interfaces. Participants traveled shorter distances, made fewer wrong turns, pointed to hidden targets more accurately and more quickly, and were able to place and label targets on maps more accurately, and more accurately estimate the virtual environment size.\}, \
keywords=\{cognition;interactive devices;user interfaces;virtual reality;RFED system;joystick interfaces;large-scale real-walking locomotion interface;navigation measures;redirected free exploration with distractors;user cognitive performance;virtual environments;virtual mazes;walking-in-place interfaces;wayfinding measures;Legged locomotion;Navigation;Prediction algorithms;Target tracking;Vectors;Virtual environments;Virtual reality;distractors;locomotion;navigation;redirection;wayfinding.;Algorithms;Analysis of Variance;Computer Graphics;Female;Humans;Male;Psychomotor Performance;Statistics, Nonparametric;User-Computer Interface;Walking\}, \
doi=\{10.1109/TVCG.2011.289\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{6081857, \
author=\{Bruder, G. and Steinicke, F. and Wieland, P. and Lappe, M.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Tuning Self-Motion Perception in Virtual Reality with Visual Illusions\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1068-1078\}, \
abstract=\{Motion perception in immersive virtual environments significantly differs from the real world. For example, previous work has shown that users tend to underestimate travel distances in virtual environments (VEs). As a solution to this problem, researchers proposed to scale the mapped virtual camera motion relative to the tracked real-world movement of a user until real and virtual motion are perceived as equal, i.e., real-world movements could be mapped with a larger gain to the VE in order to compensate for the underestimation. However, introducing discrepancies between real and virtual motion can become a problem, in particular, due to misalignments of both worlds and distorted space cognition. In this paper, we describe a different approach that introduces apparent self-motion illusions by manipulating optic flow fields during movements in VEs. These manipulations can affect self-motion perception in VEs, but omit a quantitative discrepancy between real and virtual motions. In particular, we consider to which regions of the virtual view these apparent self-motion illusions can be applied, i.e., the ground plane or peripheral vision. Therefore, we introduce four illusions and show in experiments that optic flow manipulation can significantly affect users' self-motion judgments. Furthermore, we show that with such manipulations of optic flow fields the underestimation of travel distances can be compensated.\}, \
keywords=\{image sensors;image sequences;motion estimation;virtual reality;visual perception;distorted space cognition;ground plane vision;mapped virtual camera motion;optic flow fields;peripheral vision;self-motion illusions;self-motion perception tuning;travel distance underestimation;underestimation compensation;virtual environments;virtual reality;visual illusions;Blindness;Cameras;Detectors;Optical distortion;Optical sensors;Stimulated emission;Visualization;Self-motion perception;optic flow.;virtual environments;visual illusions;Adult;Computer Graphics;Female;Humans;Illusions;Male;Motion Perception;Optic Flow;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2011.274\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5928340, \
author=\{Miao Liao and Jizhou Gao and Ruigang Yang and Minglun Gong\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Video Stereolization: Combining Motion Analysis with User Interaction\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1079-1088\}, \
abstract=\{We present a semiautomatic system that converts conventional videos into stereoscopic videos by combining motion analysis with user interaction, aiming to transfer as much as possible labeling work from the user to the computer. In addition to the widely used structure from motion (SFM) techniques, we develop two new methods that analyze the optical flow to provide additional qualitative depth constraints. They remove the camera movement restriction imposed by SFM so that general motions can be used in scene depth estimation-the central problem in mono-to-stereo conversion. With these algorithms, the user's labeling task is significantly simplified. We further developed a quadratic programming approach to incorporate both quantitative depth and qualitative depth (such as these from user scribbling) to recover dense depth maps for all frames, from which stereoscopic view can be synthesized. In addition to visual results, we present user study results showing that our approach is more intuitive and less labor intensive, while producing 3D effect comparable to that from current state-of-the-art interactive algorithms.\}, \
keywords=\{image motion analysis;image sensors;image sequences;interactive systems;quadratic programming;stereo image processing;user interfaces;video signal processing;3D effect;SFM techniques;camera movement restriction;interactive algorithms;mono-to-stereo conversion;motion analysis;optical flow analysis;quadratic programming;qualitative depth constraints;quantitative depth;scene depth estimation;semiautomatic system;stereoscopic videos;structure-from-motion techniques;user interaction;user labeling task;user scribbling;video stereolization;Cameras;Image segmentation;Image sequences;Labeling;Pixel;Quadratic programming;Three dimensional displays;Semiautomatic 2D-3D conversion;motion analysis;stereo/3D video/movie;user labeling.;Computer Graphics;Depth Perception;Humans;Imaging, Three-Dimensional;Motion;Questionnaires;Task Performance and Analysis;User-Computer Interface;Video Recording\}, \
doi=\{10.1109/TVCG.2011.114\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5999665, \
author=\{Rodgers, P. and Leishi Zhang and Purchase, H.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Wellformedness Properties in Euler Diagrams: Which Should Be Used?\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1089-1100\}, \
abstract=\{Euler diagrams are often used to visualize intersecting data sets in applications such as criminology; genetics, medicine, and computer file systems. One interesting aspect of these diagrams is that some data sets cannot be drawn without breaking one or more "wellformedness properties,\'94 which are considered to reduce the user comprehension of the diagrams. However, it is possible to draw the same data with different diagrams, each of which breaks different wellformedness properties. Hence, some properties are "swappable,\'94 so motivating the study of which of the alternatives would be best to use. This paper reports on the two empirical studies to determine how wellformedness properties affect comprehension. One study was with abstract data, the other was with concrete data that visualized students' enrollment on university modules. We have results from both studies that imply that diagrams with concurrency or disconnected zones perform less well than other some other properties. Further, we have no results that imply that diagrams with brushing points adversely affect performance. Our data also indicate that nonsimple curves are preferred less than diagrams with other properties. These results will inform both human diagram designers and the developers of automated drawing systems on the best way to visualize data using Euler diagrams.\}, \
keywords=\{data visualisation;Euler diagrams;automated drawing systems;brushing points;comprehension;computer file systems;criminology;genetics;human diagram designers;intersecting data sets visualization;medicine;student enrollment visualization;university modules;wellformedness properties;Decision support systems;Handheld computers;Euler diagrams;Venn diagrams;empirical studies;information visualization.;Color;Computer Graphics;Databases, Factual;Humans;Models, Theoretical;Research Design;Statistics as Topic\}, \
doi=\{10.1109/TVCG.2011.143\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5963665, \
author=\{Kotranza, A. and Lind, D.S. and Lok, Benjamin\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Real-Time Evaluation and Visualization of Learner Performance in a Mixed-Reality Environment for Clinical Breast Examination\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1101-1114\}, \
abstract=\{We investigate the efficacy of incorporating real-time feedback of user performance within mixed-reality environments (MREs) for training real-world tasks with tightly coupled cognitive and psychomotor components. This paper presents an approach to providing real-time evaluation and visual feedback of learner performance in an MRE for training clinical breast examination (CBE). In a user study of experienced and novice CBE practitioners (n = 69), novices receiving real-time feedback performed equivalently or better than more experienced practitioners in the completeness and correctness of the exam. A second user study (n = 8) followed novices through repeated practice of CBE in the MRE. Results indicate that skills improvement in the MRE transfers to the real-world task of CBE of human patients. This initial case study demonstrates the efficacy of MREs incorporating real-time feedback for training real-world cognitive-psychomotor tasks.\}, \
keywords=\{biomedical education;computer based training;data visualisation;medical computing;patient diagnosis;virtual reality;MRE;clinical breast examination;human patients;learner performance visualization;mixed-reality environment;psychomotor components;real-time evaluation;real-time user performance feedback;real-world cognitive-psychomotor tasks;real-world tasks training;tightly coupled cognitive components;visual feedback;Breast;Data models;Humans;Real time systems;Sensors;Training;Visualization;Mixed and augmented reality;information visualization;life and medical sciences.;Breast;Computer Graphics;Computer-Assisted Instruction;Feedback, Sensory;Female;Humans;Medical Informatics Applications;Models, Anatomic;Palpation;Pressure;User-Computer Interface\}, \
doi=\{10.1109/TVCG.2011.132\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5928343, \
author=\{Hongchuan Yu and Tong-Yee Lee and I-Cheng Yeh and Xiaosong Yang and Wenxi Li and Zhang, J.J.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{An RBF-Based Reparameterization Method for Constrained Texture Mapping\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1115-1124\}, \
abstract=\{Texture mapping has long been used in computer graphics to enhance the realism of virtual scenes. However, to match the 3D model feature points with the corresponding pixels in a texture image, surface parameterization must satisfy specific positional constraints. However, despite numerous research efforts, the construction of a mathematically robust, foldover-free parameterization that is subject to positional constraints continues to be a challenge. In the present paper, this foldover problem is addressed by developing radial basis function (RBF)-based reparameterization. Given initial 2D embedding of a 3D surface, the proposed method can reparameterize 2D embedding into a foldover-free 2D mesh, satisfying a set of user-specified constraint points. In addition, this approach is mesh free. Therefore, generating smooth texture mapping results is possible without extra smoothing optimization.\}, \
keywords=\{feature extraction;image enhancement;image matching;image texture;iterative methods;mesh generation;radial basis function networks;solid modelling;2D embedding;3D model feature point matching;3D surface;RBF-based reparameterization method;computer graphics;constrained texture mapping;foldover-free 2D mesh;foldover-free parameterization;positional constraints;radial basis function-based reparameterization;smooth texture mapping;surface parameterization;texture image;user specified constraint points;virtual scenes;Approximation methods;Computational modeling;Equations;Mesh generation;Smoothing methods;Solid modeling;Three dimensional displays;Foldover;constrained texture mapping;reparameterization.\}, \
doi=\{10.1109/TVCG.2011.117\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5963664, \
author=\{Au, O.K.-C. and Youyi Zheng and Menglin Chen and Pengfei Xu and Chiew-Lan Tai\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Mesh Segmentation with Concavity-Aware Fields\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1125-1134\}, \
abstract=\{This paper presents a simple and efficient automatic mesh segmentation algorithm that solely exploits the shape concavity information. The method locates concave creases and seams using a set of concavity-sensitive scalar fields. These fields are computed by solving a Laplacian system with a novel concavity-sensitive weighting scheme. Isolines sampled from the concavity-aware fields naturally gather at concave seams, serving as good cutting boundary candidates. In addition, the fields provide sufficient information allowing efficient evaluation of the candidate cuts. We perform a summarization of all field gradient magnitudes to define a score for each isoline and employ a score-based greedy algorithm to select the best cuts. Extensive experiments and quantitative analysis have shown that the quality of our segmentations are better than or comparable with existing state-of-the-art more complex approaches.\}, \
keywords=\{gradient methods;greedy algorithms;mesh generation;solid modelling;3D models;Laplacian system;automatic mesh segmentation algorithm;concave creases;concave seams;concavity-aware fields;concavity-sensitive scalar fields;concavity-sensitive weighting scheme;cutting boundary candidates;field gradient magnitudes;isolines;score-based greedy algorithm;shape concavity information;Boundary conditions;Computational modeling;Extremities;Face;Laplace equations;Shape;Solid modeling;Concavity-aware field;isolines.;mesh segmentation\}, \
doi=\{10.1109/TVCG.2011.131\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5975144, \
author=\{Sung-Ho Lee and Taejung Park and Jong-Hyun Kim and Chang-Hun Kim\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Adaptive Synthesis of Distance Fields\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1135-1145\}, \
abstract=\{We address the computational resource requirements of 3D example-based synthesis with an adaptive synthesis technique that uses a tree-based synthesis map. A signed-distance field (SDF) is determined for the 3D exemplars, and then new models can be synthesized as SDFs by neighborhood matching. Unlike voxel synthesis approach, our input is posed in the real domain to preserve maximum detail. In comparison to straightforward extensions to the existing volume texture synthesis approach, we made several improvements in terms of memory requirements, computation times, and synthesis quality. The inherent parallelism in this method makes it suitable for a multicore CPU. Results show that computation times and memory requirements are very much reduced, and large synthesized scenes exhibit fine details which mimic the exemplars.\}, \
keywords=\{computer games;image matching;image texture;multiprocessing systems;resource allocation;trees (mathematics);3D example-based synthesis;SDF;computation times;computational resource requirements;distance fields adaptive synthesis;memory requirements;multicore CPU;neighborhood matching;signed-distance field;synthesis quality;texture synthesis approach;tree-based synthesis map;Adaptation models;Jitter;Memory management;Octrees;Optimization;Shape;Three dimensional displays;3D shape synthesis;example-based synthesis.\}, \
doi=\{10.1109/TVCG.2011.134\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5928346, \
author=\{Xinyu Zhang and Kim, Y.J.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Simple Culling Methods for Continuous Collision Detection of Deforming Triangles\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1146-1155\}, \
abstract=\{We present a simple and efficient approach for continuous collision detection of deforming triangles based on conservative advancement. The efficiency of our approach is due to a sequence of simple collision-free conditions for deforming triangles. In our experiment, we show that our CCD algorithm achieves 2-30 times performance improvement over existing algorithms for triangle primitives.\}, \
keywords=\{computer graphics;CCD algorithm;Triangle deformation;conservative advancement;continuous collision detection;simple culling methods;Acceleration;Charge coupled devices;Equations;Face;Heuristic algorithms;Mathematical model;Solid modeling;Continuous collision detection;conservative advancement;distance computation.\}, \
doi=\{10.1109/TVCG.2011.120\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5928337, \
author=\{Lei Zhang and Hua Huang and Hongbo Fu\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{EXCOL: An EXtract-and-COmplete Layering Approach to Cartoon Animation Reusing\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1156-1169\}, \
abstract=\{We introduce the EXtract-and-COmplete Layering method (EXCOL)-a novel cartoon animation processing technique to convert a traditional animated cartoon video into multiple semantically meaningful layers. Our technique is inspired by vision-based layering techniques but focuses on shape cues in both the extraction and completion steps to reflect the unique characteristics of cartoon animation. For layer extraction, we define a novel similarity measure incorporating both shape and color of automatically segmented regions within individual frames and propagate a small set of user-specified layer labels among similar regions across frames. By clustering regions with the same labels, each frame is appropriately partitioned into different layers, with each layer containing semantically meaningful content. Then, a warping-based approach is used to fill missing parts caused by occlusion within the extracted layers to achieve a complete representation. EXCOL provides a flexible way to effectively reuse traditional cartoon animations with only a small amount of user interaction. It is demonstrated that our EXCOL method is effective and robust, and the layered representation benefits a variety of applications in cartoon animation processing.\}, \
keywords=\{computer animation;EXCOL;animated cartoon video;cartoon animation processing technique;cartoon animation reusing;extract-and-complete layering approach;shape cues;vision based layering techniques;Animation;Color;Feature extraction;Image color analysis;Image segmentation;Pixel;Shape;Cartoon animation;label propagation.;layer completion;layer extraction\}, \
doi=\{10.1109/TVCG.2011.111\}, \
ISSN=\{1077-2626\},\}\
@ARTICLE\{5963660, \
author=\{Healey, Christopher G. and Enns, J.T.\}, \
journal=\{Visualization and Computer Graphics, IEEE Transactions on\}, \
title=\{Attention and Visual Memory in Visualization and Computer Graphics\}, \
year=\{2012\}, \
month=\{July\}, \
volume=\{18\}, \
number=\{7\}, \
pages=\{1170-1188\}, \
abstract=\{A fundamental goal of visualization is to produce images of data that support visual analysis, exploration, and discovery of novel insights. An important consideration during visualization design is the role of human visual perception. How we "see\'94 details in an image can directly impact a viewer's efficiency and effectiveness. This paper surveys research on attention and visual perception, with a specific focus on results that have direct relevance to visualization and visual analytics. We discuss theories of low-level visual perception, then show how these findings form a foundation for more recent work on visual memory and visual attention. We conclude with a brief overview of how knowledge of visual attention and visual memory is being applied in visualization and graphics. We also discuss how challenges in visualization are motivating research in psychophysics.\}, \
keywords=\{data analysis;data visualisation;visual perception;attention;computer graphics;human visual perception;psychophysics;visual analysis;visual analytics;visual attention;visual memory;visualization design;Bars;Data visualization;Feature extraction;Humans;Visual perception;Visualization;Attention;color;motion;nonphotorealism;texture;visual memory;visual perception;visualization.;Attention;Computer Graphics;Humans;Memory;Models, Theoretical;Pattern Recognition, Visual;Psychophysics;Research;Visual Perception\}, \
doi=\{10.1109/TVCG.2011.127\}, \
ISSN=\{1077-2626\},\}}